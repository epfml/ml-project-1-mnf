{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./dataset_to_release/'\n",
    "train_data_path=\"./dataset_to_release/x_train.csv\"\n",
    "test_data_path=\"./dataset_to_release/x_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids=load_csv_data_all(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path=\"./dataset/x_train.csv\"\n",
    "# train_label_path=\"./dataset/y_train.csv\"\n",
    "# train_data=pd.read_csv(train_data_path)\n",
    "# train_label=pd.read_csv(train_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data points\n",
    "# xb=load_csv_data(train_data_path,sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the labels \n",
    "# yb=load_csv_data_labels(train_label_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y = np.expand_dims(yb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names from the x_train.csv and convert it into a list\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handeling the missing values\n",
    "\n",
    "def replace_nan_by_mean(data):\n",
    "    ''' function that handels the missing values by replacing them with the column means'''\n",
    "    nan_indices = np.isnan(data)\n",
    "    column_means = np.nanmean(data, axis=0)\n",
    "    data[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train=replace_nan_by_mean(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifying that the nan values have been successfully removed\n",
    "# matrix=np.isnan(data_train)\n",
    "# num_true=np.count_nonzero(matrix)\n",
    "# num_false = matrix.size - num_true\n",
    "# print(num_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtering: we only keep relevent features\n",
    "\n",
    "def filtering(data, data_path):\n",
    "    columns=extract_first_line(data_path).split(',')\n",
    "    columns.pop(0)\n",
    "    columns_to_keep=[]\n",
    "    for c in columns:\n",
    "        if c.startswith('_'):\n",
    "            columns_to_keep.append(c)\n",
    "    indices_to_keep = [columns.index(c) for c in columns_to_keep]\n",
    "    data_f=data[:, indices_to_keep]\n",
    "    return(data_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_filtered=filtering(data_train, train_data_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of the data\n",
    "def standardize(data):\n",
    "    mean=np.mean(data, axis=0)\n",
    "    std=np.std(data, axis=0)\n",
    "    return((data - mean) / (std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_standardized = standardize(data_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the test set in two\n",
    "\n",
    "\n",
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8\n",
    "    you will have 80% of your data set dedicated to training\n",
    "    and the rest dedicated to testing. If ratio times the number of samples is not round\n",
    "    you can use np.floor. Also check the documentation for np.random.permutation,\n",
    "    it could be useful.\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        y: numpy array of shape (N,).\n",
    "        ratio: scalar in [0,1]\n",
    "        seed: integer.\n",
    "\n",
    "    Returns:\n",
    "        x_tr: numpy array containing the train data.\n",
    "        x_te: numpy array containing the test data.\n",
    "        y_tr: numpy array containing the train labels.\n",
    "        y_te: numpy array containing the test labels.\n",
    "    \"\"\"\n",
    "    N=int(ratio*len(x))\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # split the data based on the given ratio: \n",
    "    shuffled_data=np.random.permutation(x)\n",
    "    #print(shuffled_data)\n",
    "    np.random.seed(seed)\n",
    "    shuffled_labels=np.random.permutation(y)\n",
    "    #print(shuffled_labels)\n",
    "    x_tr=shuffled_data[:N] #train data\n",
    "    x_te=shuffled_data[N:] #test data\n",
    "    y_tr=shuffled_labels[:N]#train labels\n",
    "    y_te=shuffled_labels[N:]# test labels\n",
    "\n",
    "    return(x_tr,x_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr,x_te, y_tr, y_te=split_data(data_standardized, y_train, ratio=0.8)\n",
    "#y_te=np.expand_dims(y_te, 1)\n",
    "#y_tr=np.expand_dims(y_tr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262508, 1) (262508, 75)\n"
     ]
    }
   ],
   "source": [
    "#print(y_tr.shape, x_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.expand_dims(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification using logistic regression\n",
    "\n",
    "max_iters = 10000\n",
    "gamma = 0.5\n",
    "\n",
    " # build tx\n",
    "tx_tr = np.c_[np.ones((y_train.shape[0], 1)), data_standardized]\n",
    "initial_w=np.zeros((tx_tr.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == -1, 0, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad=calculate_log_likelihood_gradient(y_train,tx_tr,initial_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20559754369390645 0.03185866857918228\n"
     ]
    }
   ],
   "source": [
    "# w=initial_w-gamma*grad\n",
    "# print(np.min(w), np.max(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6031907630182123\n"
     ]
    }
   ],
   "source": [
    "# loss=calculate_log_likelihood_loss(y_train,tx_tr,initial_w)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6030287143641271\n",
      "Current iteration=100, loss=0.2508686434767057\n",
      "Current iteration=200, loss=0.24930194108636033\n",
      "Current iteration=300, loss=0.24902538226118237\n",
      "Current iteration=400, loss=0.24894621240064338\n",
      "Current iteration=500, loss=0.24891299793724914\n",
      "Current iteration=600, loss=0.24889282517295436\n",
      "Current iteration=700, loss=0.2488773650326659\n",
      "Current iteration=800, loss=0.24886423950609554\n",
      "Current iteration=900, loss=0.24885264188892714\n",
      "Current iteration=1000, loss=0.24884221835471887\n",
      "Current iteration=1100, loss=0.2488327645612468\n",
      "Current iteration=1200, loss=0.2488241372356895\n",
      "Current iteration=1300, loss=0.2488162252318069\n",
      "Current iteration=1400, loss=0.24880893813753485\n",
      "Current iteration=1500, loss=0.24880220064664463\n",
      "Current iteration=1600, loss=0.24879594916608747\n",
      "Current iteration=1700, loss=0.2487901294876123\n",
      "Current iteration=1800, loss=0.24878469506948184\n",
      "Current iteration=1900, loss=0.24877960571607194\n",
      "Current iteration=2000, loss=0.24877482653775781\n",
      "Current iteration=2100, loss=0.24877032711739805\n",
      "Current iteration=2200, loss=0.24876608083353602\n",
      "Current iteration=2300, loss=0.24876206430491127\n",
      "Current iteration=2400, loss=0.2487582569303554\n",
      "Current iteration=2500, loss=0.24875464050466978\n",
      "Current iteration=2600, loss=0.24875119889570968\n",
      "Current iteration=2700, loss=0.24874791777126234\n",
      "Current iteration=2800, loss=0.24874478436679295\n",
      "Current iteration=2900, loss=0.24874178728700233\n",
      "Current iteration=3000, loss=0.24873891633555503\n",
      "Current iteration=3100, loss=0.2487361623684325\n",
      "Current iteration=3200, loss=0.24873351716721145\n",
      "Current iteration=3300, loss=0.24873097332923472\n",
      "Current iteration=3400, loss=0.24872852417217106\n",
      "Current iteration=3500, loss=0.24872616365087882\n",
      "Current iteration=3600, loss=0.24872388628483388\n",
      "Current iteration=3700, loss=0.24872168709465248\n",
      "Current iteration=3800, loss=0.24871956154647137\n",
      "Current iteration=3900, loss=0.24871750550313257\n",
      "Current iteration=4000, loss=0.2487155151812732\n",
      "Current iteration=4100, loss=0.24871358711355251\n",
      "Current iteration=4200, loss=0.2487117181153564\n",
      "Current iteration=4300, loss=0.24870990525540895\n",
      "Current iteration=4400, loss=0.24870814582980247\n",
      "Current iteration=4500, loss=0.24870643733901926\n",
      "Current iteration=4600, loss=0.24870477746757616\n",
      "Current iteration=4700, loss=0.2487031640659725\n",
      "Current iteration=4800, loss=0.24870159513466247\n",
      "Current iteration=4900, loss=0.24870006880980747\n",
      "Current iteration=5000, loss=0.2486985833505968\n",
      "Current iteration=5100, loss=0.24869713712795147\n",
      "Current iteration=5200, loss=0.24869572861444836\n",
      "Current iteration=5300, loss=0.24869435637532067\n",
      "Current iteration=5400, loss=0.248693019060413\n",
      "Current iteration=5500, loss=0.24869171539697799\n",
      "Current iteration=5600, loss=0.24869044418321978\n",
      "Current iteration=5700, loss=0.24868920428250052\n",
      "Current iteration=5800, loss=0.24868799461813218\n",
      "Current iteration=5900, loss=0.24868681416869132\n",
      "Current iteration=6000, loss=0.2486856619637963\n",
      "Current iteration=6100, loss=0.24868453708029686\n",
      "Current iteration=6200, loss=0.2486834386388317\n",
      "Current iteration=6300, loss=0.24868236580071085\n",
      "Current iteration=6400, loss=0.24868131776509295\n",
      "Current iteration=6500, loss=0.2486802937664204\n",
      "loss=0.24867975054251806\n"
     ]
    }
   ],
   "source": [
    "w,loss= logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6031907630182123\n",
      "Current iteration=100, loss=0.2520887951460211\n",
      "Current iteration=200, loss=0.25039224509073077\n",
      "Current iteration=300, loss=0.2500521566247474\n",
      "Current iteration=400, loss=0.24993664541267355\n",
      "Current iteration=500, loss=0.2498842695901215\n",
      "Current iteration=600, loss=0.24985524379278526\n",
      "Current iteration=700, loss=0.24983655399036112\n",
      "Current iteration=800, loss=0.24982309818208762\n",
      "Current iteration=900, loss=0.24981262703336746\n",
      "Current iteration=1000, loss=0.2498040556914796\n",
      "Current iteration=1100, loss=0.24979681368238313\n",
      "Current iteration=1200, loss=0.24979057224301943\n",
      "Current iteration=1300, loss=0.24978512356961943\n",
      "Current iteration=1400, loss=0.249780324917527\n",
      "Current iteration=1500, loss=0.2497760714712832\n",
      "Current iteration=1600, loss=0.2497722824081014\n",
      "Current iteration=1700, loss=0.24976889323836618\n",
      "Current iteration=1800, loss=0.24976585127206166\n",
      "Current iteration=1900, loss=0.249763112732196\n",
      "Current iteration=2000, loss=0.24976064079449578\n",
      "Current iteration=2100, loss=0.24975840418504383\n",
      "Current iteration=2200, loss=0.24975637613661977\n",
      "Current iteration=2300, loss=0.2497545335889742\n",
      "Current iteration=2400, loss=0.2497528565626392\n",
      "Current iteration=2500, loss=0.24975132766052677\n",
      "Current iteration=2600, loss=0.249749931666108\n",
      "Current iteration=2700, loss=0.24974865521604003\n",
      "Current iteration=2800, loss=0.24974748653106987\n",
      "Current iteration=2900, loss=0.24974641519312069\n",
      "loss=0.24974610137078704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lambda_ = 0.0005\n",
    "# w_reg,loss_reg= reg_logistic_regression(y_train, tx_tr, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_te=np.c_[np.ones((y_te.shape[0], 1)), x_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te=np.where(y_te==-1, 0, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(test, model):\n",
    "    pred=(sigmoid(test.dot(model))>=0.5).astype(int)\n",
    "    return(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=apply_model(tx_te, w_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy\n",
    "correct_predictions = np.sum(y_pred == y_te)\n",
    "total_samples = len(y_te)\n",
    "accuracy = correct_predictions / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9106312950462462\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=replace_nan_by_mean(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.98439905e+00],\n",
       "       [-6.71278927e-04],\n",
       "       [ 2.87138546e-03],\n",
       "       [ 1.59538068e-02],\n",
       "       [ 1.53392851e-03],\n",
       "       [ 3.76353710e-02],\n",
       "       [ 2.07579264e-02],\n",
       "       [-7.23643419e-03],\n",
       "       [ 4.91416283e-04],\n",
       "       [ 4.91416283e-04],\n",
       "       [-9.81921163e-03],\n",
       "       [ 4.61033861e-02],\n",
       "       [-3.26303386e-02],\n",
       "       [ 5.86030010e-03],\n",
       "       [ 2.26074356e-01],\n",
       "       [ 3.89504974e-02],\n",
       "       [ 2.04549791e-01],\n",
       "       [-1.29211982e-01],\n",
       "       [ 1.26911369e-01],\n",
       "       [ 1.84269871e-02],\n",
       "       [ 7.67404993e-02],\n",
       "       [-1.09742873e-01],\n",
       "       [-1.50566704e-01],\n",
       "       [-1.62424355e-01],\n",
       "       [ 1.74814008e-01],\n",
       "       [ 1.21415129e-02],\n",
       "       [ 4.29799725e-02],\n",
       "       [ 1.09373738e-02],\n",
       "       [-7.62468874e-02],\n",
       "       [ 2.45340791e-02],\n",
       "       [ 2.62838941e-01],\n",
       "       [-8.93709087e-02],\n",
       "       [ 7.63636773e-01],\n",
       "       [ 5.83425844e-02],\n",
       "       [ 3.36706373e-02],\n",
       "       [ 1.34704159e-01],\n",
       "       [-6.52823855e-02],\n",
       "       [-2.50762842e-02],\n",
       "       [-6.46279331e-02],\n",
       "       [-9.86335257e-02],\n",
       "       [-2.90634165e-01],\n",
       "       [ 2.12836319e-01],\n",
       "       [-1.70654382e-02],\n",
       "       [ 4.03529308e-01],\n",
       "       [-3.90336176e-01],\n",
       "       [ 3.63176042e-02],\n",
       "       [ 3.97145839e-02],\n",
       "       [ 1.23305940e-01],\n",
       "       [ 6.07259783e-02],\n",
       "       [ 4.67729404e-04],\n",
       "       [-3.29423725e-02],\n",
       "       [ 2.12610013e-01],\n",
       "       [ 9.36415041e-02],\n",
       "       [-2.21534671e-02],\n",
       "       [-1.24664783e-02],\n",
       "       [-1.20603812e-01],\n",
       "       [-5.97489189e-02],\n",
       "       [ 4.56574966e-02],\n",
       "       [ 4.74162132e-03],\n",
       "       [ 1.16932460e-03],\n",
       "       [ 1.69241553e-01],\n",
       "       [-1.13364919e-01],\n",
       "       [ 3.17946062e-02],\n",
       "       [-1.85402786e-02],\n",
       "       [-1.64476946e-01],\n",
       "       [-1.03937528e-01],\n",
       "       [-3.45575572e-02],\n",
       "       [ 1.41939992e-01],\n",
       "       [ 1.56886992e-02],\n",
       "       [ 2.63380809e-02],\n",
       "       [-8.93762204e-02],\n",
       "       [-5.15897472e-02],\n",
       "       [ 1.92704481e-01],\n",
       "       [ 1.03932296e-02],\n",
       "       [-5.39275320e-02],\n",
       "       [ 8.49469359e-05]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_filtered=filtering(xt, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 75)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xt_filtered_standardized=standardize(xt_filtered)\n",
    "xtest=np.c_[np.ones((xt.shape[0], 1)), xt_filtered_standardized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 76)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=apply_model(xtest, w)\n",
    "predictions=np.where(predictions==0,-1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, predictions, 'predictions_v1_with_logistic_regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
