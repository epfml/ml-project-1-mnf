{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 269,
=======
   "execution_count": 1,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ###"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 270,
=======
   "execution_count": 2,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./dataset_to_release/'\n",
    "train_data_path=\"./dataset_to_release/x_train.csv\"\n",
    "test_data_path=\"./dataset_to_release/x_test.csv\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 271,
=======
   "execution_count": 3,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids=load_csv_data_all(data_path, sub_sample=False)"
   ]
  },
  {
<<<<<<< HEAD
   "attachments": {},
=======
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 272,
=======
   "execution_count": 9,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the missing values\n",
    "\n",
    "def replace_nan_by_mean(data):\n",
    "    ''' function that handels the missing values by replacing them with the column means'''\n",
    "    nan_indices = np.isnan(data)\n",
    "    column_means = np.nanmean(data, axis=0)\n",
    "    data[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "    return data\n",
    "\n",
    "data_train = replace_nan_by_mean(x_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 273,
=======
   "execution_count": 11,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 273,
=======
     "execution_count": 11,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 274,
=======
   "execution_count": 12,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 274,
=======
     "execution_count": 12,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 275,
=======
   "execution_count": 13,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtering: we only keep relevant features\n",
    "\n",
    "def filtering(data, data_path):\n",
    "    columns = extract_first_line(data_path).split(',')\n",
    "    columns.pop(0)\n",
    "    columns_to_keep = []\n",
    "    for c in columns:\n",
    "        if c.startswith('_'):\n",
    "            columns_to_keep.append(c)\n",
    "    indices_to_keep = [columns.index(c) for c in columns_to_keep]\n",
    "    data_f = data[:, indices_to_keep]\n",
    "    return(data_f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 276,
=======
   "execution_count": 14,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\"_AGE80\", \"_AGE65YR\", \"_AGEG5YR\", \"_AGE_G\", \"_AIDTST3\", \"_ASTHMS1\", \"_BMI5\", \"_BMI5CAT\", \"_CASTHM1\", \"_CHLDCNT\", \"_CHOLCHK\", \"_DRDXAR1\", \"_DRNKWEK\", \"_DUALCOR\", \"_DUALUSE\", \"_EDUCAG\", \"_FLSHOT6\", \"_FRT16\", \"_FRTLT1\", \"_FRTRESP\", \"_FRUITEX\", \"_FRUTSUM\", \"_HCVU651\", \"_HISPANC\", \"_INCOMG\", \"_LLCPWT\", \"_LMTACT1\", \"_LMTSCL1\", \"_LMTWRK1\", \"_LTASTH1\", \"_MICHD\", \"_MINAC11\", \"_MINAC21\", \"_MISFRTN\", \"_MISVEGN\", \"_MRACE1\", \"_PA30021\", \"_PA150R2\", \"_PA300R2\", \"_PACAT1\", \"_PAINDX1\", \"_PAREC1\", \"_PASTAE1\", \"_PASTRNG\", \"_PNEUMO2\", \"_PRACE1\", \"_RACE\", \"_RACEG21\", \"_RACEGR3\", \"_RACE_G1\", \"_RFBING5\", \"_RFBMI5\", \"_RFCHOL\", \"_RFDRHV5\", \"_RFHLTH\", \"_RFHYPE5\", \"_RFSEAT2\", \"_RFSEAT3\", \"_RFSMOK3\", \"_SMOKER3\", \"_TOTINDA\", \"_VEG23\", \"_VEGESUM\", \"_VEGETEX\", \"_VEGLT1\", \"_VEGRESP\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 277,
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secode version of data filtering, remove 9 more columns\n",
    "def filtering_2(data,data_path):\n",
    "    columns = extract_first_line(data_path).split(',')\n",
    "    columns.pop(0)\n",
    "    filtered_columns = [col for col in columns if col in features_to_keep]\n",
    "    indices_to_keep = [columns.index(c) for c in filtered_columns]\n",
    "    print(len(indices_to_keep))\n",
    "\n",
    "    data_f = data[:, indices_to_keep]\n",
    "    return(data_f)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 278,
=======
   "execution_count": 17,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "data_train_filtered_2=filtering_2(data_train, train_data_path)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 279,
=======
   "execution_count": 18,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 65)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 279,
=======
     "execution_count": 18,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_filtered_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 280,
=======
   "execution_count": 19,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of the data\n",
    "def standardize(data):\n",
    "    small_value=1*10**(-9)\n",
    "    mean=np.mean(data, axis=0)\n",
    "    std=np.std(data, axis=0)+small_value\n",
    "    return((data - mean) / (std))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_standard=standardize(data_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
=======
   "execution_count": 21,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature augmentation\n",
    "def feature_expansion(data, degree):\n",
    "    augmented_features=[]\n",
    "    for i in range(data.shape[1]):\n",
    "        feature=data[:,i]\n",
    "        augmented_feature=build_poly(feature, degree)\n",
    "        augmented_features.append(augmented_feature)\n",
    "\n",
    "    # Stack the augmented features horizontally\n",
    "    augmented_data = np.hstack(augmented_features)\n",
    "    return(augmented_data)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 283,
=======
   "execution_count": 22,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Computes the F1 score for a classification model using NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    true_labels (numpy.ndarray): True labels for the data.\n",
    "    predicted_labels (numpy.ndarray): Predicted labels from the model.\n",
    "\n",
    "    Returns:\n",
    "    f1 (float): The F1 score.\n",
    "    \"\"\"\n",
    "    true_positive = np.sum(np.logical_and(true_labels == 1, predicted_labels == 1))\n",
    "    false_positive = np.sum(np.logical_and(true_labels == 0, predicted_labels == 1))\n",
    "    false_negative = np.sum(np.logical_and(true_labels == 1, predicted_labels == 0))\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 284,
=======
   "execution_count": 23,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "\n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval : (k + 1) * interval] for k in range(k_fold)]\n",
    "    \n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 285,
=======
   "execution_count": 24,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(test, model, thresh = 0.5):\n",
    "    pred=(sigmoid(test.dot(model))>=thresh).astype(int)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 286,
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 65)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_filtered_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "\n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        lambda_:    scalar, cf. ridge_regression()\n",
    "        degree:     scalar, cf. build_poly()\n",
    "\n",
    "    Returns:\n",
    "        train and test root mean square errors rmse = sqrt(2 mse)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # get k'th subgroup in test, others in train:\n",
    "    train_idx=np.reshape(k_indices[[i for i in range(len(k_indices)) if i!=k]], -1)\n",
    "    test_idx=k_indices[k]\n",
    "\n",
    "    x_train=x[train_idx,:]\n",
    "    print(x_train.shape)\n",
    "    y_train=y[train_idx]\n",
    "    x_test=x[test_idx,:]\n",
    "    y_test=y[test_idx]\n",
    "    \n",
    "    y_tr=np.expand_dims(y_train, 1)\n",
    "    y_te=np.expand_dims(y_test, 1)\n",
    "\n",
    "    y_tr=np.where(y_tr == -1, 0, y_tr)\n",
    "    print(y_tr, y_tr.shape)\n",
    "    y_te=np.where(y_te == -1, 0, y_te)\n",
    "\n",
    "    max_iters = 1000\n",
    "    gamma=0.5\n",
    "\n",
    "    # ***************************************************\n",
    "    # form data with polynomial degree: \n",
    "    print('on va auggmenter le data')\n",
    "    train_data=feature_expansion(x_train, degree)\n",
    "    test_data=feature_expansion(x_test, degree)\n",
    "    train_data=standardize(train_data)\n",
    "    test_data=standardize(test_data)\n",
    "    # ***************************************************\n",
    "     # build tx\n",
    "    tx_tr = np.c_[np.ones((y_train.shape[0], 1)), train_data]\n",
    "    tx_te = np.c_[np.ones((test_data.shape[0], 1)), test_data]\n",
    "    print(tx_tr.shape)\n",
    "    print(tx_te.shape)\n",
    "    initial_w=np.zeros((tx_tr.shape[1], 1))\n",
    "\n",
    "    # reg logistic regression: \n",
    "    w=reg_logistic_regression(y_tr,tx_tr,lambda_,initial_w, max_iters, gamma)[0]\n",
    "    print(w.shape)\n",
    "    print(tx_te.shape)\n",
    "    y_pred=apply_model(tx_te, w, 0.5)\n",
    "    # calculate f1 score on test:\n",
    "    f1_te=compute_f1_score(y_te, y_pred)\n",
    "  \n",
    "    return f1_te"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 293,
=======
   "execution_count": 33,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_demo(degree, k_fold, lambdas):\n",
    "    \"\"\"cross validation over regularisation parameter lambda.\n",
    "\n",
    "    Args:\n",
    "        degree: integer, degree of the polynomial expansion\n",
    "        k_fold: integer, the number of folds\n",
    "        lambdas: shape = (p, ) where p is the number of values of lambda to test\n",
    "    Returns:\n",
    "        best_lambda : scalar, value of the best lambda\n",
    "        best_rmse : scalar, the associated root mean squared error for the best lambda\n",
    "    \"\"\"\n",
    "\n",
    "    seed = 12\n",
    "    #degree = degree\n",
    "    k_fold = k_fold\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_train, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
<<<<<<< HEAD
    "    f1_score=np.zeros((len(degree), len(lambdas)))\n",
    "    # cross validation over lambdas:\n",
    "    for i in range(len(degree)):\n",
    "        d=degree[i]\n",
    "        for j in range(len(lambdas)):\n",
    "            lambda_=lambdas[j]\n",
    "            cross_val=[cross_validation(y_train, data_train_filtered_2, k_indices, k, lambda_, d) for k in range(k_fold)]\n",
    "            f1=np.mean(cross_val)\n",
    "            f1_score[i,j]=f1\n",
    "    print('on y est presque')\n",
    "    best_degree=degree[np.unravel_index(np.argmax(f1_score, axis=None), f1_score.shape)[0]]\n",
    "    best_lambda=lambdas[np.unravel_index(np.argmax(f1_score, axis=None), f1_score.shape)[1]]\n",
    "    best_f1=np.max(f1_score)\n",
=======
    "    f1_score = []\n",
    "    # cross validation over lambdas:\n",
    "    for d in degree:\n",
    "        cross_val = [cross_validation(y_train, data_train_filtered_2, k_indices, k, lambda_, d) for k in range(k_fold)]\n",
    "        f1 = np.mean(cross_val)\n",
    "        f1_score.append(f1)\n",
    "    print('on y est presque')\n",
    "    best_degree = degree[np.argmax(f1_score)]\n",
    "    best_f1 = np.min(f1_score)\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
    "    # print(\n",
    "    #     \"For polynomial expansion up to degree %.f, the choice of lambda which leads to the best test rmse is %.5f with a test rmse of %.3f\"\n",
    "    #     % (degree, best_lambda, f1_score)\n",
    "    # )\n",
<<<<<<< HEAD
    "    return best_degree, best_f1 , best_lambda , f1_score"
=======
    "    return best_degree, best_f1, f1_score"
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 294,
=======
   "execution_count": 34,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135,)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 294,
=======
     "execution_count": 34,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 295,
=======
   "execution_count": 35,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6031271020869903\n",
      "Current iteration=100, loss=0.2508818609584282\n",
      "Current iteration=200, loss=0.24929958625602125\n",
      "Current iteration=300, loss=0.24901103140858183\n",
      "Current iteration=400, loss=0.24892184353322086\n",
      "Current iteration=500, loss=0.2488818344044575\n",
      "Current iteration=600, loss=0.24885752867320482\n",
      "Current iteration=700, loss=0.24883967608154337\n",
      "Current iteration=800, loss=0.24882519690837746\n",
      "Current iteration=900, loss=0.24881284707599244\n",
      "loss=0.24880212385553394\n",
=======
      "Current iteration=0, loss=0.6031271020869896\n",
      "Current iteration=100, loss=0.2507973231123299\n",
      "Current iteration=200, loss=0.24924630680398083\n",
      "Current iteration=300, loss=0.2489755077280358\n",
      "Current iteration=400, loss=0.24889727970199313\n",
      "Current iteration=500, loss=0.24886350174454194\n",
      "Current iteration=600, loss=0.24884235012557887\n",
      "Current iteration=700, loss=0.24882582642474602\n",
      "Current iteration=800, loss=0.24881166149241313\n",
      "Current iteration=900, loss=0.2487990871437696\n",
      "loss=0.24878787054760435\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6030464334324384\n",
      "Current iteration=100, loss=0.25046958950405673\n",
      "Current iteration=200, loss=0.24888597076115862\n",
      "Current iteration=300, loss=0.24859830522941606\n",
      "Current iteration=400, loss=0.24851104760632747\n",
      "Current iteration=500, loss=0.24847318713330568\n",
      "Current iteration=600, loss=0.24845098221093267\n",
      "Current iteration=700, loss=0.2484350992621882\n",
      "Current iteration=800, loss=0.24842242902645797\n",
      "Current iteration=900, loss=0.24841171990439512\n",
      "loss=0.24840245903633865\n",
=======
      "Current iteration=0, loss=0.6030464334324386\n",
      "Current iteration=100, loss=0.25038515240587816\n",
      "Current iteration=200, loss=0.24883294041135184\n",
      "Current iteration=300, loss=0.2485629896646563\n",
      "Current iteration=400, loss=0.24848672289618903\n",
      "Current iteration=500, loss=0.2484551674729943\n",
      "Current iteration=600, loss=0.24843620493394464\n",
      "Current iteration=700, loss=0.24842174564705205\n",
      "Current iteration=800, loss=0.24840948804905388\n",
      "Current iteration=900, loss=0.2483986537513867\n",
      "loss=0.24838899613169801\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6031845958855026\n",
      "Current iteration=100, loss=0.25142624091835974\n",
      "Current iteration=200, loss=0.24985206245098962\n",
      "Current iteration=300, loss=0.24956640266502336\n",
      "Current iteration=400, loss=0.24947993333083582\n",
      "Current iteration=500, loss=0.24944233174313898\n",
      "Current iteration=600, loss=0.2494201104025351\n",
      "Current iteration=700, loss=0.24940406726343242\n",
      "Current iteration=800, loss=0.24939116139304843\n",
      "Current iteration=900, loss=0.24938017803451715\n",
      "loss=0.24937062827644754\n",
=======
      "Current iteration=0, loss=0.6031845958855018\n",
      "Current iteration=100, loss=0.2513422693884829\n",
      "Current iteration=200, loss=0.24979933463264384\n",
      "Current iteration=300, loss=0.24953121626205493\n",
      "Current iteration=400, loss=0.24945565282609913\n",
      "Current iteration=500, loss=0.24942431136580082\n",
      "Current iteration=600, loss=0.24940530310913903\n",
      "Current iteration=700, loss=0.2493906614571757\n",
      "Current iteration=800, loss=0.24937814891512347\n",
      "Current iteration=900, loss=0.24936702108815065\n",
      "loss=0.24935705372521327\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6031154207371573\n",
      "Current iteration=100, loss=0.2510661551528343\n",
      "Current iteration=200, loss=0.24945400108991794\n",
      "Current iteration=300, loss=0.24915604069413547\n",
      "Current iteration=400, loss=0.24906460828955837\n",
      "Current iteration=500, loss=0.24902469455264548\n",
      "Current iteration=600, loss=0.2490012581638707\n",
      "Current iteration=700, loss=0.24898451255209875\n",
      "Current iteration=800, loss=0.24897117701156773\n",
      "Current iteration=900, loss=0.2489599264906412\n",
      "loss=0.24895021537585746\n",
=======
      "Current iteration=0, loss=0.6031154207371584\n",
      "Current iteration=100, loss=0.2509813902448809\n",
      "Current iteration=200, loss=0.2494001416248767\n",
      "Current iteration=300, loss=0.2491199170879072\n",
      "Current iteration=400, loss=0.2490396501640447\n",
      "Current iteration=500, loss=0.2490062077409033\n",
      "Current iteration=600, loss=0.2489861306149474\n",
      "Current iteration=700, loss=0.24897087709806245\n",
      "Current iteration=800, loss=0.24895798666895413\n",
      "Current iteration=900, loss=0.24894662008393326\n",
      "loss=0.24893650747012822\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
<<<<<<< HEAD
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031271020869903\n",
      "Current iteration=100, loss=0.25175380601850067\n",
      "Current iteration=200, loss=0.2500391540788391\n",
      "Current iteration=300, loss=0.2497026911411405\n",
      "Current iteration=400, loss=0.24959290358298766\n",
      "Current iteration=500, loss=0.24954642966728224\n",
      "Current iteration=600, loss=0.24952253190011017\n",
      "Current iteration=700, loss=0.24950802469589253\n",
      "Current iteration=800, loss=0.24949799910238246\n",
      "Current iteration=900, loss=0.2494904430025482\n",
      "loss=0.24948450073548495\n",
      "(131, 1)\n",
      "(82033, 131)\n",
=======
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019478618578422\n",
      "Current iteration=100, loss=0.24370899632204585\n",
      "Current iteration=200, loss=0.2397801107659406\n",
      "Current iteration=300, loss=0.23865336038069948\n",
      "Current iteration=400, loss=0.23819688848899484\n",
      "Current iteration=500, loss=0.23796180605849862\n",
      "Current iteration=600, loss=0.23781405121951693\n",
      "Current iteration=700, loss=0.23770660247154984\n",
      "Current iteration=800, loss=0.23762083794538158\n",
      "Current iteration=900, loss=0.23754847784240818\n",
      "loss=0.2374859817057645\n",
      "(196, 1)\n",
      "(82033, 196)\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
<<<<<<< HEAD
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6030464334324384\n",
      "Current iteration=100, loss=0.2513410653139847\n",
      "Current iteration=200, loss=0.24962389428951345\n",
      "Current iteration=300, loss=0.24928795458205114\n",
      "Current iteration=400, loss=0.24917931815659458\n",
      "Current iteration=500, loss=0.24913413165099657\n",
      "Current iteration=600, loss=0.24911149258066384\n",
      "Current iteration=700, loss=0.2490981348801897\n",
      "Current iteration=800, loss=0.24908912132012098\n",
      "Current iteration=900, loss=0.24908243932165017\n",
      "loss=0.24907723756104053\n",
      "(131, 1)\n",
      "(82033, 131)\n",
=======
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6018842183925996\n",
      "Current iteration=100, loss=0.24323599211269245\n",
      "Current iteration=200, loss=0.23926280357184682\n",
      "Current iteration=300, loss=0.2381159880909555\n",
      "Current iteration=400, loss=0.23765220297961362\n",
      "Current iteration=500, loss=0.23741515533805635\n",
      "Current iteration=600, loss=0.23726742790281716\n",
      "Current iteration=700, loss=0.23716063634745943\n",
      "Current iteration=800, loss=0.23707564340003628\n",
      "Current iteration=900, loss=0.237003990391979\n",
      "loss=0.23694207978044177\n",
      "(196, 1)\n",
      "(82033, 196)\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
<<<<<<< HEAD
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031845958855026\n",
      "Current iteration=100, loss=0.2522934231527271\n",
      "Current iteration=200, loss=0.2505862191521215\n",
      "Current iteration=300, loss=0.2502527572688576\n",
      "Current iteration=400, loss=0.25014506222984434\n",
      "Current iteration=500, loss=0.2501002693797611\n",
      "Current iteration=600, loss=0.25007778175982864\n",
      "Current iteration=700, loss=0.25006445208410144\n",
      "Current iteration=800, loss=0.25005540032221385\n",
      "Current iteration=900, loss=0.2500486456485712\n",
      "loss=0.25004335621806545\n",
      "(131, 1)\n",
      "(82033, 131)\n",
=======
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.601994856181849\n",
      "Current iteration=100, loss=0.24420858185344993\n",
      "Current iteration=200, loss=0.24029169845825507\n",
      "Current iteration=300, loss=0.2391679552544864\n",
      "Current iteration=400, loss=0.23870951211982375\n",
      "Current iteration=500, loss=0.2384709385526982\n",
      "Current iteration=600, loss=0.2383197250449261\n",
      "Current iteration=700, loss=0.23820935150945355\n",
      "Current iteration=800, loss=0.2381212618548898\n",
      "Current iteration=900, loss=0.23804709651270242\n",
      "loss=0.23798321817371448\n",
      "(196, 1)\n",
      "(82033, 196)\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
<<<<<<< HEAD
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031154207371573\n",
      "Current iteration=100, loss=0.25194011093207874\n",
      "Current iteration=200, loss=0.2501983653044403\n",
      "Current iteration=300, loss=0.24985274574462538\n",
      "Current iteration=400, loss=0.24973975992353695\n",
      "Current iteration=500, loss=0.24969234564548443\n",
      "Current iteration=600, loss=0.24966842900866784\n",
      "Current iteration=700, loss=0.2496542641920603\n",
      "Current iteration=800, loss=0.24964469812804962\n",
      "Current iteration=900, loss=0.2496376136003289\n",
      "loss=0.24963210774960734\n",
      "(131, 1)\n",
      "(82033, 131)\n",
=======
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019262460044708\n",
      "Current iteration=100, loss=0.2437761816205908\n",
      "Current iteration=200, loss=0.23979010192359174\n",
      "Current iteration=300, loss=0.23864021155288107\n",
      "Current iteration=400, loss=0.23817262730434902\n",
      "Current iteration=500, loss=0.2379315937877351\n",
      "Current iteration=600, loss=0.2377803996205717\n",
      "Current iteration=700, loss=0.2376708500015386\n",
      "Current iteration=800, loss=0.2375837399947509\n",
      "Current iteration=900, loss=0.23751047054404054\n",
      "loss=0.23744731996199744\n",
      "(196, 1)\n",
      "(82033, 196)\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
<<<<<<< HEAD
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031271020869903\n",
      "Current iteration=100, loss=0.2661093232466152\n",
      "Current iteration=200, loss=0.2656788684715289\n",
      "Current iteration=300, loss=0.26565909719905606\n",
      "Current iteration=400, loss=0.2656556394715942\n",
      "loss=0.2656551421533349\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6030464334324384\n",
      "Current iteration=100, loss=0.26571230797451334\n",
      "Current iteration=200, loss=0.2652783325353499\n",
      "Current iteration=300, loss=0.26525834180630353\n",
      "Current iteration=400, loss=0.26525493790869853\n",
      "loss=0.2652544863203525\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031845958855026\n",
      "Current iteration=100, loss=0.26661764176361447\n",
      "Current iteration=200, loss=0.26618591705165834\n",
      "Current iteration=300, loss=0.2661662279021511\n",
      "Current iteration=400, loss=0.26616290660774755\n",
      "loss=0.2661624854245358\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031154207371573\n",
      "Current iteration=100, loss=0.26631104668994315\n",
      "Current iteration=200, loss=0.2658712697469119\n",
      "Current iteration=300, loss=0.26585023629622767\n",
      "Current iteration=400, loss=0.2658465930711045\n",
      "loss=0.26584604736457174\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031271020869903\n",
      "loss=0.3907805781748347\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6030464334324384\n",
      "loss=0.39053042650271486\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031845958855026\n",
      "loss=0.3911361772161226\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 131)\n",
      "(82033, 131)\n",
      "Current iteration=0, loss=0.6031154207371573\n",
      "loss=0.39095012313604877\n",
      "(131, 1)\n",
      "(82033, 131)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019478618578429\n",
      "Current iteration=100, loss=0.2438230785018909\n",
      "Current iteration=200, loss=0.23988202230847985\n",
      "Current iteration=300, loss=0.23873985669737138\n",
      "Current iteration=400, loss=0.23827005552248248\n",
      "Current iteration=500, loss=0.23802557159423404\n",
      "Current iteration=600, loss=0.23787218878375507\n",
      "Current iteration=700, loss=0.23776208689116687\n",
      "Current iteration=800, loss=0.23767579844255768\n",
      "Current iteration=900, loss=0.23760435508379146\n",
      "loss=0.23754369223915864\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6018842183926011\n",
      "Current iteration=100, loss=0.24335038148262592\n",
      "Current iteration=200, loss=0.23936573016382148\n",
      "Current iteration=300, loss=0.23820385531476643\n",
      "Current iteration=400, loss=0.23772669982918493\n",
      "Current iteration=500, loss=0.23748000635480485\n",
      "Current iteration=600, loss=0.23732635680724415\n",
      "Current iteration=700, loss=0.23721664677036025\n",
      "Current iteration=800, loss=0.23713092036967076\n",
      "Current iteration=900, loss=0.2370600317604864\n",
      "loss=0.23699985208244034\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019948561818482\n",
      "Current iteration=100, loss=0.24432230053970216\n",
      "Current iteration=200, loss=0.2403932157992211\n",
      "Current iteration=300, loss=0.23925423154803624\n",
      "Current iteration=400, loss=0.23878275361552478\n",
      "Current iteration=500, loss=0.23853509364882977\n",
      "Current iteration=600, loss=0.23837852325696188\n",
      "Current iteration=700, loss=0.23826569913456727\n",
      "Current iteration=800, loss=0.23817722002516226\n",
      "Current iteration=900, loss=0.23810404947169064\n",
      "loss=0.23804204036646612\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019262460044701\n",
      "Current iteration=100, loss=0.24389091708284877\n",
      "Current iteration=200, loss=0.2398931914344785\n",
      "Current iteration=300, loss=0.23872808670106968\n",
      "Current iteration=400, loss=0.23824722176448546\n",
      "Current iteration=500, loss=0.23799675582479948\n",
      "Current iteration=600, loss=0.23783986420047032\n",
      "Current iteration=700, loss=0.2377275769460562\n",
      "Current iteration=800, loss=0.2376398574051491\n",
      "Current iteration=900, loss=0.23756742690401692\n",
      "loss=0.2375060463100302\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019478618578429\n",
      "Current iteration=100, loss=0.24495613389455595\n",
      "Current iteration=200, loss=0.24106388136585438\n",
      "Current iteration=300, loss=0.23992857839364215\n",
      "Current iteration=400, loss=0.2394577951454362\n",
      "Current iteration=500, loss=0.2392195981405424\n",
      "Current iteration=600, loss=0.239081486131502\n",
      "Current iteration=700, loss=0.2389930917650806\n",
      "Current iteration=800, loss=0.23893212871430433\n",
      "Current iteration=900, loss=0.23888760560947384\n",
      "loss=0.23885394771868756\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6018842183926011\n",
      "Current iteration=100, loss=0.24448647134580878\n",
      "Current iteration=200, loss=0.24055629235696374\n",
      "Current iteration=300, loss=0.23940404977801585\n",
      "Current iteration=400, loss=0.2389261698724562\n",
      "Current iteration=500, loss=0.23868502406173903\n",
      "Current iteration=600, loss=0.23854576402650357\n",
      "Current iteration=700, loss=0.23845703511172506\n",
      "Current iteration=800, loss=0.23839610300554576\n",
      "Current iteration=900, loss=0.2383517611553494\n",
      "loss=0.2383183279623263\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019948561818482\n",
      "Current iteration=100, loss=0.24545229979296498\n",
      "Current iteration=200, loss=0.24157097363709815\n",
      "Current iteration=300, loss=0.2404391704111467\n",
      "Current iteration=400, loss=0.23996810096839524\n",
      "Current iteration=500, loss=0.23972845815433866\n",
      "Current iteration=600, loss=0.23958875253769601\n",
      "Current iteration=700, loss=0.23949892673260414\n",
      "Current iteration=800, loss=0.23943676296477331\n",
      "Current iteration=900, loss=0.2393912629656777\n",
      "loss=0.2393568304685879\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019262460044701\n",
      "Current iteration=100, loss=0.24502983802218736\n",
      "Current iteration=200, loss=0.2410854692320459\n",
      "Current iteration=300, loss=0.23992928833160723\n",
      "Current iteration=400, loss=0.23944848674833158\n",
      "Current iteration=500, loss=0.23920489451199678\n",
      "Current iteration=600, loss=0.2390636479373931\n",
      "Current iteration=700, loss=0.23897333703160725\n",
      "Current iteration=800, loss=0.23891115738900995\n",
      "Current iteration=900, loss=0.23886583775879872\n",
      "loss=0.2388316479592041\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019478618578429\n",
      "Current iteration=100, loss=0.26139178928091816\n",
      "Current iteration=200, loss=0.2602605527846164\n",
      "Current iteration=300, loss=0.26011647788644515\n",
      "Current iteration=400, loss=0.260091378896338\n",
      "Current iteration=500, loss=0.2600864553947371\n",
      "loss=0.26008572741886826\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6018842183926011\n",
      "Current iteration=100, loss=0.2609603667931641\n",
      "Current iteration=200, loss=0.259818994092297\n",
      "Current iteration=300, loss=0.2596730799388259\n",
      "Current iteration=400, loss=0.25964769148313305\n",
      "Current iteration=500, loss=0.2596427322198129\n",
      "loss=0.25964200280514443\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019948561818482\n",
      "Current iteration=100, loss=0.2618672996951364\n",
      "Current iteration=200, loss=0.2607367787500419\n",
      "Current iteration=300, loss=0.2605935725556254\n",
      "Current iteration=400, loss=0.26056866807467466\n",
      "Current iteration=500, loss=0.2605637650955274\n",
      "loss=0.2605630358390098\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019262460044701\n",
      "Current iteration=100, loss=0.2615169669824201\n",
      "Current iteration=200, loss=0.2603642195482881\n",
      "Current iteration=300, loss=0.26021716082026475\n",
      "Current iteration=400, loss=0.2601915027360494\n",
      "Current iteration=500, loss=0.26018646292865977\n",
      "loss=0.26018569777975037\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019478618578429\n",
      "Current iteration=100, loss=0.5115102127744313\n",
      "Current iteration=200, loss=0.5115102023117165\n",
      "Current iteration=300, loss=0.5115102023116302\n",
      "Current iteration=400, loss=0.5115102023116304\n",
      "Current iteration=500, loss=0.5115102023116304\n",
      "Current iteration=600, loss=0.5115102023116304\n",
      "Current iteration=700, loss=0.5115102023116304\n",
      "Current iteration=800, loss=0.5115102023116304\n",
      "Current iteration=900, loss=0.5115102023116304\n",
      "loss=0.4060611182395154\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6018842183926011\n",
      "Current iteration=100, loss=0.5121006822216337\n",
      "Current iteration=200, loss=0.5121006726200383\n",
      "Current iteration=300, loss=0.5121006726199523\n",
      "Current iteration=400, loss=0.5121006726199521\n",
      "Current iteration=500, loss=0.512100672619952\n",
      "Current iteration=600, loss=0.512100672619952\n",
      "Current iteration=700, loss=0.512100672619952\n",
      "Current iteration=800, loss=0.5121006726199523\n",
      "Current iteration=900, loss=0.5121006726199521\n",
      "loss=0.4056131733907581\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019948561818482\n",
      "Current iteration=100, loss=0.5119590348076947\n",
      "Current iteration=200, loss=0.5119590248441257\n",
      "Current iteration=300, loss=0.5119590248440414\n",
      "Current iteration=400, loss=0.5119590248440414\n",
      "Current iteration=500, loss=0.5119590248440415\n",
      "Current iteration=600, loss=0.5119590248440414\n",
      "Current iteration=700, loss=0.5119590248440414\n",
      "Current iteration=800, loss=0.5119590248440414\n",
      "Current iteration=900, loss=0.5119590248440415\n",
      "loss=0.40640323193265215\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 196)\n",
      "(82033, 196)\n",
      "Current iteration=0, loss=0.6019262460044701\n",
      "Current iteration=100, loss=0.5109189902247756\n",
      "Current iteration=200, loss=0.5109189803287734\n",
      "Current iteration=300, loss=0.5109189803286872\n",
      "Current iteration=400, loss=0.5109189803286871\n",
      "Current iteration=500, loss=0.5109189803286872\n",
      "Current iteration=600, loss=0.5109189803286872\n",
      "Current iteration=700, loss=0.5109189803286872\n",
      "Current iteration=800, loss=0.5109189803286872\n",
      "Current iteration=900, loss=0.5109189803286872\n",
      "loss=0.4059894313541864\n",
      "(196, 1)\n",
      "(82033, 196)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066688275217945\n",
      "Current iteration=100, loss=0.24289751188022654\n",
      "Current iteration=200, loss=0.23884623549911518\n",
      "Current iteration=300, loss=0.23797228467340525\n",
      "Current iteration=400, loss=0.2377041436905686\n",
      "Current iteration=500, loss=0.23755859940636426\n",
      "Current iteration=600, loss=0.23745143835758042\n",
      "Current iteration=700, loss=0.2373656459051402\n",
      "Current iteration=800, loss=0.23729408598303833\n",
      "Current iteration=900, loss=0.23723294265702802\n",
      "loss=0.23718035072008664\n",
=======
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066688275217922\n",
      "Current iteration=100, loss=0.24267326221027363\n",
      "Current iteration=200, loss=0.23866223725108796\n",
      "Current iteration=300, loss=0.2378907551914231\n",
      "Current iteration=400, loss=0.23766069215302904\n",
      "Current iteration=500, loss=0.23751897175819361\n",
      "Current iteration=600, loss=0.23741168700814425\n",
      "Current iteration=700, loss=0.23732411123278196\n",
      "Current iteration=800, loss=0.23725001458634262\n",
      "Current iteration=900, loss=0.2371860387948295\n",
      "loss=0.2371305742213453\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6066060206653102\n",
      "Current iteration=100, loss=0.24228827137328723\n",
      "Current iteration=200, loss=0.23825576706611076\n",
      "Current iteration=300, loss=0.2374182805986703\n",
      "Current iteration=400, loss=0.2371652944490199\n",
      "Current iteration=500, loss=0.23701939094806793\n",
      "Current iteration=600, loss=0.23691166954039145\n",
      "Current iteration=700, loss=0.236825238112966\n",
      "Current iteration=800, loss=0.23675288777521802\n",
      "Current iteration=900, loss=0.236690815135357\n",
      "loss=0.23663719991203397\n",
=======
      "Current iteration=0, loss=0.6066060206653054\n",
      "Current iteration=100, loss=0.24206492749130443\n",
      "Current iteration=200, loss=0.2380800621102849\n",
      "Current iteration=300, loss=0.23734947834598857\n",
      "Current iteration=400, loss=0.23712140475061383\n",
      "Current iteration=500, loss=0.23697908719387648\n",
      "Current iteration=600, loss=0.23687137774776237\n",
      "Current iteration=700, loss=0.23678319995907238\n",
      "Current iteration=800, loss=0.23670827223365332\n",
      "Current iteration=900, loss=0.2366432683018203\n",
      "loss=0.2365866409290753\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6066918017401889\n",
      "Current iteration=100, loss=0.24343063525140704\n",
      "Current iteration=200, loss=0.23938457844202568\n",
      "Current iteration=300, loss=0.23848424523870715\n",
      "Current iteration=400, loss=0.23819684182819498\n",
      "Current iteration=500, loss=0.23804691851805648\n",
      "Current iteration=600, loss=0.2379379105914617\n",
      "Current iteration=700, loss=0.23785124493481258\n",
      "Current iteration=800, loss=0.2377793555527589\n",
      "Current iteration=900, loss=0.23771818984144963\n",
      "loss=0.23766574857694567\n",
=======
      "Current iteration=0, loss=0.6066918017401913\n",
      "Current iteration=100, loss=0.24320550265373886\n",
      "Current iteration=200, loss=0.2391959967461437\n",
      "Current iteration=300, loss=0.23839243951687691\n",
      "Current iteration=400, loss=0.23815191759358298\n",
      "Current iteration=500, loss=0.2380065200627373\n",
      "Current iteration=600, loss=0.23789741418611057\n",
      "Current iteration=700, loss=0.23780906781186603\n",
      "Current iteration=800, loss=0.23773477428000817\n",
      "Current iteration=900, loss=0.23767091201572113\n",
      "loss=0.23761572516662136\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6066781169323511\n",
      "Current iteration=100, loss=0.2425305354918528\n",
      "Current iteration=200, loss=0.23860412597289485\n",
      "Current iteration=300, loss=0.2379189795560445\n",
      "Current iteration=400, loss=0.23767639097120616\n",
      "Current iteration=500, loss=0.2375268707816992\n",
      "Current iteration=600, loss=0.237417026929187\n",
      "Current iteration=700, loss=0.23732929382900464\n",
      "Current iteration=800, loss=0.2372560934113445\n",
      "Current iteration=900, loss=0.23719343570679058\n",
      "loss=0.23713940388680604\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066688275217945\n",
      "Current iteration=100, loss=0.2451152531911699\n",
      "Current iteration=200, loss=0.24113293492878934\n",
      "Current iteration=300, loss=0.24022601105892952\n",
      "Current iteration=400, loss=0.23990002726079282\n",
      "Current iteration=500, loss=0.23974550829782001\n",
      "Current iteration=600, loss=0.2396552908441513\n",
      "Current iteration=700, loss=0.239594575218816\n",
      "Current iteration=800, loss=0.23955004891439455\n",
      "Current iteration=900, loss=0.2395157364317208\n",
      "loss=0.23907308973198915\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066060206653102\n",
      "Current iteration=100, loss=0.24450253657883592\n",
      "Current iteration=200, loss=0.24052242595826756\n",
      "Current iteration=300, loss=0.23961107696958162\n",
      "Current iteration=400, loss=0.23928253374269937\n",
      "Current iteration=500, loss=0.23912680094245944\n",
      "Current iteration=600, loss=0.23903603169417545\n",
      "Current iteration=700, loss=0.23897502213966085\n",
      "Current iteration=800, loss=0.23893027719853616\n",
      "Current iteration=900, loss=0.23889575352503595\n",
      "loss=0.23848950677643022\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066918017401889\n",
      "Current iteration=100, loss=0.2456562678916867\n",
      "Current iteration=200, loss=0.24168929681720275\n",
      "Current iteration=300, loss=0.2407782429440437\n",
      "Current iteration=400, loss=0.24044741117560037\n",
      "Current iteration=500, loss=0.24028923528210272\n",
      "Current iteration=600, loss=0.24019650263780107\n",
      "Current iteration=700, loss=0.2401341283992377\n",
      "Current iteration=800, loss=0.24008854098173624\n",
      "Current iteration=900, loss=0.24005356848099293\n",
      "loss=0.2395869132659069\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066781169323511\n",
      "Current iteration=100, loss=0.24471120785578124\n",
      "Current iteration=200, loss=0.2407419591675016\n",
      "Current iteration=300, loss=0.23982934361271732\n",
      "Current iteration=400, loss=0.23949862853538667\n",
      "Current iteration=500, loss=0.23934115373974524\n",
      "Current iteration=600, loss=0.23924911671173454\n",
      "Current iteration=700, loss=0.2391872327001908\n",
      "Current iteration=800, loss=0.2391419061701883\n",
      "Current iteration=900, loss=0.2391070034513581\n",
      "loss=0.23883197841839302\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066688275217945\n",
      "Current iteration=100, loss=0.2772992246291408\n",
      "Current iteration=200, loss=0.2764092087153942\n",
      "Current iteration=300, loss=0.2763392191581869\n",
      "Current iteration=400, loss=0.2763290859524024\n",
      "Current iteration=500, loss=0.27632697472257856\n",
      "Current iteration=600, loss=0.2763264329473729\n",
      "Current iteration=700, loss=0.27632627848392793\n",
      "Current iteration=800, loss=0.2763262319718777\n",
      "Current iteration=900, loss=0.2763262175203098\n",
      "loss=0.2616668778460812\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066060206653102\n",
      "Current iteration=100, loss=0.2765419679218594\n",
      "Current iteration=200, loss=0.27585705363403557\n",
      "Current iteration=300, loss=0.27578669048237087\n",
      "Current iteration=400, loss=0.2757766005586856\n",
      "Current iteration=500, loss=0.27577451935921565\n",
      "Current iteration=600, loss=0.2757739871113696\n",
      "Current iteration=700, loss=0.2757738352019424\n",
      "Current iteration=800, loss=0.27577378931217617\n",
      "Current iteration=900, loss=0.27577377499429684\n",
      "loss=0.261166193324101\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066918017401889\n",
      "Current iteration=100, loss=0.2776828885971709\n",
      "Current iteration=200, loss=0.27702114146195095\n",
      "Current iteration=300, loss=0.2769511403647917\n",
      "Current iteration=400, loss=0.27694081969405104\n",
      "Current iteration=500, loss=0.27693864800259077\n",
      "Current iteration=600, loss=0.2769380907760882\n",
      "Current iteration=700, loss=0.27693793268254524\n",
      "Current iteration=800, loss=0.2769378853528081\n",
      "Current iteration=900, loss=0.2769378707244669\n",
      "loss=0.26215868816233073\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066781169323511\n",
      "Current iteration=100, loss=0.27672517034726063\n",
      "Current iteration=200, loss=0.27586025660263\n",
      "Current iteration=300, loss=0.27578892602772276\n",
      "Current iteration=400, loss=0.2757786034779363\n",
      "Current iteration=500, loss=0.275776465562236\n",
      "Current iteration=600, loss=0.2757759205266794\n",
      "Current iteration=700, loss=0.2757757658679239\n",
      "Current iteration=800, loss=0.27577571941881585\n",
      "Current iteration=900, loss=0.27577570499937876\n",
      "loss=0.2616780703226955\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066688275217945\n",
      "Current iteration=100, loss=0.8243797614989106\n",
      "Current iteration=200, loss=0.8243797422540937\n",
      "Current iteration=300, loss=0.8243797422540056\n",
      "Current iteration=400, loss=0.8243797422540058\n",
      "Current iteration=500, loss=0.824379742254006\n",
      "Current iteration=600, loss=0.8243797422540058\n",
      "Current iteration=700, loss=0.8243797422540057\n",
      "Current iteration=800, loss=0.8243797422540058\n",
      "Current iteration=900, loss=0.8243797422540058\n",
      "loss=0.4369382149654254\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066060206653102\n",
      "Current iteration=100, loss=0.827485648768348\n",
      "Current iteration=200, loss=0.8274856308602486\n",
      "Current iteration=300, loss=0.8274856308601707\n",
      "Current iteration=400, loss=0.8274856308601707\n",
      "Current iteration=500, loss=0.8274856308601706\n",
      "Current iteration=600, loss=0.8274856308601706\n",
      "Current iteration=700, loss=0.8274856308601705\n",
      "Current iteration=800, loss=0.8274856308601707\n",
      "Current iteration=900, loss=0.8274856308601705\n",
      "loss=0.43610545150311053\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066918017401889\n",
      "Current iteration=100, loss=0.8251569187475193\n",
      "Current iteration=200, loss=0.8251569010976358\n",
      "Current iteration=300, loss=0.8251569010975538\n",
      "Current iteration=400, loss=0.8251569010975535\n",
      "Current iteration=500, loss=0.825156901097553\n",
      "Current iteration=600, loss=0.8251569010975527\n",
      "Current iteration=700, loss=0.8251569010975529\n",
      "Current iteration=800, loss=0.8251569010975532\n",
      "Current iteration=900, loss=0.8251569010975538\n",
      "loss=0.43713639361892254\n",
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 261)\n",
      "(82033, 261)\n",
      "Current iteration=0, loss=0.6066781169323511\n",
      "Current iteration=100, loss=0.823504843011839\n",
      "Current iteration=200, loss=0.8235048248856522\n",
      "Current iteration=300, loss=0.8235048248855719\n",
      "Current iteration=400, loss=0.8235048248855719\n",
      "Current iteration=500, loss=0.8235048248855715\n",
      "Current iteration=600, loss=0.823504824885572\n",
      "Current iteration=700, loss=0.8235048248855719\n",
      "Current iteration=800, loss=0.8235048248855719\n",
      "Current iteration=900, loss=0.8235048248855714\n",
      "loss=0.43644306774562747\n",
=======
      "Current iteration=0, loss=0.6066781169323513\n",
      "Current iteration=100, loss=0.24231224574862567\n",
      "Current iteration=200, loss=0.23847075756276184\n",
      "Current iteration=300, loss=0.23786404457088703\n",
      "Current iteration=400, loss=0.23763177551062512\n",
      "Current iteration=500, loss=0.23748582221629108\n",
      "Current iteration=600, loss=0.23737603972832252\n",
      "Current iteration=700, loss=0.2372866120882689\n",
      "Current iteration=800, loss=0.23721088459324743\n",
      "Current iteration=900, loss=0.23714533979519503\n",
      "loss=0.2370883321426239\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(261, 1)\n",
      "(82033, 261)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6160815304850482\n",
      "Current iteration=100, loss=0.24404104126439666\n",
      "Current iteration=200, loss=0.2418077112495461\n",
      "Current iteration=300, loss=0.24129830992039808\n",
      "Current iteration=400, loss=0.24106630866082318\n",
      "Current iteration=500, loss=0.24092006784860454\n",
      "Current iteration=600, loss=0.24081270739690205\n",
      "Current iteration=700, loss=0.24072777720615898\n",
      "Current iteration=800, loss=0.2406577887458321\n",
      "Current iteration=900, loss=0.24059862916431676\n",
      "loss=0.24603597335398283\n",
=======
      "Current iteration=0, loss=0.6160815304850422\n",
      "Current iteration=100, loss=0.24389405830057173\n",
      "Current iteration=200, loss=0.24170140448615887\n",
      "Current iteration=300, loss=0.24120430402285012\n",
      "Current iteration=400, loss=0.24097616269506802\n",
      "Current iteration=500, loss=0.2408294591737368\n",
      "Current iteration=600, loss=0.24071980216839606\n",
      "Current iteration=700, loss=0.24063192422035676\n",
      "Current iteration=800, loss=0.24055885610868952\n",
      "Current iteration=900, loss=0.2404966978184482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.2456469378717906\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6160010015839368\n",
      "Current iteration=100, loss=0.24345707050363805\n",
      "Current iteration=200, loss=0.24119805256633112\n",
      "Current iteration=300, loss=0.2406796891956446\n",
      "Current iteration=400, loss=0.2404442199834015\n",
      "Current iteration=500, loss=0.24029557764616188\n",
      "Current iteration=600, loss=0.2401859777826878\n",
      "Current iteration=700, loss=0.24009878861719253\n",
      "Current iteration=800, loss=0.24002651458846366\n",
      "Current iteration=900, loss=0.23996507557822103\n",
      "loss=0.24525203637391074\n",
=======
      "Current iteration=0, loss=0.6160010015839307\n",
      "Current iteration=100, loss=0.24331247924509683\n",
      "Current iteration=200, loss=0.24108998922495803\n",
      "Current iteration=300, loss=0.24058398369389122\n",
      "Current iteration=400, loss=0.2403524811312662\n",
      "Current iteration=500, loss=0.24020337602958217\n",
      "Current iteration=600, loss=0.24009137784306844\n",
      "Current iteration=700, loss=0.2400010685442561\n",
      "Current iteration=800, loss=0.23992549796426157\n",
      "Current iteration=900, loss=0.23986081684217456\n",
      "loss=0.24486198897849082\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6160508901420394\n",
      "Current iteration=100, loss=0.2445770694651521\n",
      "Current iteration=200, loss=0.24232117949962345\n",
      "Current iteration=300, loss=0.2418012763780806\n",
      "Current iteration=400, loss=0.24156442827187696\n",
      "Current iteration=500, loss=0.2414164768289606\n",
      "Current iteration=600, loss=0.24130889503966205\n",
      "Current iteration=700, loss=0.24122444431107976\n",
      "Current iteration=800, loss=0.2411552710612783\n",
      "Current iteration=900, loss=0.24109708655489512\n",
      "loss=0.24658485738878952\n",
=======
      "Current iteration=0, loss=0.6160508901420431\n",
      "Current iteration=100, loss=0.2444284548423153\n",
      "Current iteration=200, loss=0.2422145817336045\n",
      "Current iteration=300, loss=0.24170659684254656\n",
      "Current iteration=400, loss=0.24147350685966942\n",
      "Current iteration=500, loss=0.2413251881114785\n",
      "Current iteration=600, loss=0.24121548725903602\n",
      "Current iteration=700, loss=0.24112828318932383\n",
      "Current iteration=800, loss=0.2410562163516469\n",
      "Current iteration=900, loss=0.24099520528602195\n",
      "loss=0.2461933597107624\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6161435013613481\n",
      "Current iteration=100, loss=0.25166468569202577\n",
      "Current iteration=200, loss=0.24746946869150196\n",
      "Current iteration=300, loss=0.2464272144862899\n",
      "Current iteration=400, loss=0.24600554056257654\n",
      "Current iteration=500, loss=0.2457819473991012\n",
      "Current iteration=600, loss=0.24563926414256732\n",
      "Current iteration=700, loss=0.2455362513197996\n",
      "Current iteration=800, loss=0.24545584814121355\n",
      "Current iteration=900, loss=0.24538997564675352\n",
      "loss=0.2403256126687667\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160815304850482\n",
      "Current iteration=100, loss=0.24586085030872987\n",
      "Current iteration=200, loss=0.24304861393595475\n",
      "Current iteration=300, loss=0.24254187382835357\n",
      "Current iteration=400, loss=0.24233795374332698\n",
      "Current iteration=500, loss=0.24222635207752136\n",
      "Current iteration=600, loss=0.24215315852678743\n",
      "Current iteration=700, loss=0.24210015737540985\n",
      "Current iteration=800, loss=0.2420596774217534\n",
      "Current iteration=900, loss=0.2420278107200373\n",
      "loss=0.25005102292235254\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160010015839368\n",
      "Current iteration=100, loss=0.24524104567009\n",
      "Current iteration=200, loss=0.24245326052168908\n",
      "Current iteration=300, loss=0.24193793849757753\n",
      "Current iteration=400, loss=0.2417308859032416\n",
      "Current iteration=500, loss=0.24161772007864982\n",
      "Current iteration=600, loss=0.2415434231130536\n",
      "Current iteration=700, loss=0.2414894546862962\n",
      "Current iteration=800, loss=0.2414480649049848\n",
      "Current iteration=900, loss=0.24141533768343032\n",
      "loss=0.24927774488735993\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160508901420394\n",
      "Current iteration=100, loss=0.24641476751428687\n",
      "Current iteration=200, loss=0.24356342386411955\n",
      "Current iteration=300, loss=0.24304842161627105\n",
      "Current iteration=400, loss=0.2428403251636179\n",
      "Current iteration=500, loss=0.24272678276677653\n",
      "Current iteration=600, loss=0.24265282600458485\n",
      "Current iteration=700, loss=0.24259968459318232\n",
      "Current iteration=800, loss=0.24255938388054157\n",
      "Current iteration=900, loss=0.2425278478047121\n",
      "loss=0.25062160642590514\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6161435013613481\n",
      "Current iteration=100, loss=0.2557583991705082\n",
      "Current iteration=200, loss=0.2509181265529457\n",
      "Current iteration=300, loss=0.2500411398283729\n",
      "Current iteration=400, loss=0.24973135535327493\n",
      "Current iteration=500, loss=0.24958439626578174\n",
      "Current iteration=600, loss=0.24949743841107086\n",
      "Current iteration=700, loss=0.24943816943624475\n",
      "Current iteration=800, loss=0.24939439691364912\n",
      "Current iteration=900, loss=0.24936059555368384\n",
      "loss=0.24182604793087975\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160815304850482\n",
      "Current iteration=100, loss=0.27137007637110966\n",
      "Current iteration=200, loss=0.2708694682614081\n",
      "Current iteration=300, loss=0.27082831932764956\n",
      "Current iteration=400, loss=0.27082136745326174\n",
      "Current iteration=500, loss=0.27081971040913894\n",
      "Current iteration=600, loss=0.27081924800488133\n",
      "Current iteration=700, loss=0.2708191105762536\n",
      "Current iteration=800, loss=0.2708190681922854\n",
      "Current iteration=900, loss=0.2708190548153145\n",
      "loss=0.26214384349816666\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160010015839368\n",
      "Current iteration=100, loss=0.27069796208683833\n",
      "Current iteration=200, loss=0.2701732936930327\n",
      "Current iteration=300, loss=0.27013643002996574\n",
      "Current iteration=400, loss=0.27012812791499025\n",
      "Current iteration=500, loss=0.2701268842999588\n",
      "Current iteration=600, loss=0.2701263049995993\n",
      "Current iteration=700, loss=0.2701262003791686\n",
      "Current iteration=800, loss=0.27012614763495224\n",
      "Current iteration=900, loss=0.2701261367665728\n",
      "loss=0.26150793008437284\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160508901420394\n",
      "Current iteration=100, loss=0.2718752118680404\n",
      "Current iteration=200, loss=0.27137084689197905\n",
      "Current iteration=300, loss=0.27132881615427995\n",
      "Current iteration=400, loss=0.2713216625910028\n",
      "Current iteration=500, loss=0.271319963763707\n",
      "Current iteration=600, loss=0.2713194947956193\n",
      "Current iteration=700, loss=0.27131935658852496\n",
      "Current iteration=800, loss=0.2713193142624476\n",
      "Current iteration=900, loss=0.2713193009742244\n",
      "loss=0.2626568162012845\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6161435013613481\n",
      "Current iteration=100, loss=0.2633971612965733\n",
      "Current iteration=200, loss=0.26287978043146093\n",
      "Current iteration=300, loss=0.26283794566687907\n",
      "Current iteration=400, loss=0.26283078098291485\n",
      "Current iteration=500, loss=0.26282902488102816\n",
      "Current iteration=600, loss=0.262828527544147\n",
      "Current iteration=700, loss=0.2628283770364727\n",
      "Current iteration=800, loss=0.26282832977497217\n",
      "Current iteration=900, loss=0.2628283145775399\n",
      "loss=0.2565586437342485\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160815304850482\n",
      "Current iteration=100, loss=0.586172863890302\n",
      "Current iteration=200, loss=0.5861725078556543\n",
      "Current iteration=300, loss=0.5861725078541672\n",
      "Current iteration=400, loss=0.5861725078541673\n",
      "Current iteration=500, loss=0.5861725078541672\n",
      "Current iteration=600, loss=0.5861725078541672\n",
      "Current iteration=700, loss=0.5861725078541672\n",
      "Current iteration=800, loss=0.5861725078541671\n",
      "Current iteration=900, loss=0.5861725078541672\n",
      "loss=1.358703175973327\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160010015839368\n",
      "Current iteration=100, loss=0.5842404481398492\n",
      "Current iteration=200, loss=0.5842400739542861\n",
      "Current iteration=300, loss=0.5842400739527506\n",
      "Current iteration=400, loss=0.5842400739527507\n",
      "Current iteration=500, loss=0.5842400739527506\n",
      "Current iteration=600, loss=0.5842400739527507\n",
      "Current iteration=700, loss=0.5842400739527507\n",
      "Current iteration=800, loss=0.5842400739527507\n",
      "Current iteration=900, loss=0.5842400739527507\n",
      "loss=1.3667470722476864\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6160508901420394\n",
      "Current iteration=100, loss=0.5840147452377024\n",
      "Current iteration=200, loss=0.5840143928534346\n",
      "Current iteration=300, loss=0.5840143928519484\n",
      "Current iteration=400, loss=0.5840143928519488\n",
      "Current iteration=500, loss=0.5840143928519488\n",
      "Current iteration=600, loss=0.5840143928519488\n",
      "Current iteration=700, loss=0.5840143928519488\n",
      "Current iteration=800, loss=0.5840143928519488\n",
      "Current iteration=900, loss=0.5840143928519484\n",
      "loss=1.3604314569681615\n",
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 326)\n",
      "(82033, 326)\n",
      "Current iteration=0, loss=0.6161435013613481\n",
      "Current iteration=100, loss=1.3603822489199437\n",
      "Current iteration=200, loss=1.3603820605271744\n",
      "Current iteration=300, loss=1.3603820605268775\n",
      "Current iteration=400, loss=1.360382060526878\n",
      "Current iteration=500, loss=1.3603820605268775\n",
      "Current iteration=600, loss=1.360382060526878\n",
      "Current iteration=700, loss=1.360382060526878\n",
      "Current iteration=800, loss=1.360382060526878\n",
      "Current iteration=900, loss=1.360382060526878\n",
      "loss=0.583379697361311\n",
=======
      "Current iteration=0, loss=0.6161435013613472\n",
      "Current iteration=100, loss=0.25131959120407904\n",
      "Current iteration=200, loss=0.24713031147074488\n",
      "Current iteration=300, loss=0.2460799989162624\n",
      "Current iteration=400, loss=0.24565004320498096\n",
      "Current iteration=500, loss=0.2454190245391787\n",
      "Current iteration=600, loss=0.24527004321476162\n",
      "Current iteration=700, loss=0.24516170255950587\n",
      "Current iteration=800, loss=0.2450767130876434\n",
      "Current iteration=900, loss=0.24500680597580296\n",
      "loss=0.24021524040681466\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(326, 1)\n",
      "(82033, 326)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6291388172144947\n",
      "Current iteration=100, loss=0.24416974055184984\n",
      "Current iteration=200, loss=0.2460366839905867\n",
      "Current iteration=300, loss=0.24399938856158837\n",
      "Current iteration=400, loss=0.24416333908344545\n",
      "Current iteration=500, loss=0.24406715680596788\n",
      "Current iteration=600, loss=0.24398315203561463\n",
      "Current iteration=700, loss=0.2439082581885974\n",
      "Current iteration=800, loss=0.2438427804961029\n",
      "Current iteration=900, loss=0.2437856440024642\n",
      "loss=0.24008439645052979\n",
=======
      "Current iteration=0, loss=0.629138817214484\n",
      "Current iteration=100, loss=0.24316232091135237\n",
      "Current iteration=200, loss=0.24554429314935436\n",
      "Current iteration=300, loss=0.24431485638964087\n",
      "Current iteration=400, loss=0.24428828659323684\n",
      "Current iteration=500, loss=0.24420789346681232\n",
      "Current iteration=600, loss=0.24412600401304088\n",
      "Current iteration=700, loss=0.24405052460448615\n",
      "Current iteration=800, loss=0.2439833413334223\n",
      "Current iteration=900, loss=0.24392410289490893\n",
      "loss=0.24008865467844753\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6290271451482715\n",
      "Current iteration=100, loss=0.24888838534179056\n",
      "Current iteration=200, loss=0.2427680717741414\n",
      "Current iteration=300, loss=0.2438325598712638\n",
      "Current iteration=400, loss=0.24359195856358137\n",
      "Current iteration=500, loss=0.2435027330699779\n",
      "Current iteration=600, loss=0.24341530018057025\n",
      "Current iteration=700, loss=0.24333670086498962\n",
      "Current iteration=800, loss=0.2432675451582162\n",
      "Current iteration=900, loss=0.24320692607830827\n",
      "loss=0.23952361956746618\n",
=======
      "Current iteration=0, loss=0.6290271451482649\n",
      "Current iteration=100, loss=0.24997315024169975\n",
      "Current iteration=200, loss=0.24308514732192887\n",
      "Current iteration=300, loss=0.24380140136913822\n",
      "Current iteration=400, loss=0.24372927148302184\n",
      "Current iteration=500, loss=0.24364711907960998\n",
      "Current iteration=600, loss=0.2435618969821118\n",
      "Current iteration=700, loss=0.24348253594947303\n",
      "Current iteration=800, loss=0.2434114002935111\n",
      "Current iteration=900, loss=0.24334836470554902\n",
      "loss=0.2395253856183207\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.6290281605444632\n",
      "Current iteration=100, loss=0.2481025952608064\n",
      "Current iteration=200, loss=0.2438286540324744\n",
      "Current iteration=300, loss=0.24497779533691827\n",
      "Current iteration=400, loss=0.24468276827729932\n",
      "Current iteration=500, loss=0.24460159968923828\n",
      "Current iteration=600, loss=0.24452165738551462\n",
      "Current iteration=700, loss=0.24445073008392504\n",
      "Current iteration=800, loss=0.2443888433492467\n",
      "Current iteration=900, loss=0.2443349150422637\n",
      "loss=0.24062599046079486\n",
=======
      "Current iteration=0, loss=0.6290281605444663\n",
      "Current iteration=100, loss=0.2490257620155882\n",
      "Current iteration=200, loss=0.24413915867488956\n",
      "Current iteration=300, loss=0.24490091065179415\n",
      "Current iteration=400, loss=0.24481983677623825\n",
      "Current iteration=500, loss=0.24474374531041954\n",
      "Current iteration=600, loss=0.24466665335443988\n",
      "Current iteration=700, loss=0.24459572396039975\n",
      "Current iteration=800, loss=0.24453263550753246\n",
      "Current iteration=900, loss=0.24447703824906689\n",
      "loss=0.24063001955348032\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
<<<<<<< HEAD
      "Current iteration=0, loss=0.629269994479424\n",
      "Current iteration=100, loss=0.24773038597953176\n",
      "Current iteration=200, loss=0.24657194166856625\n",
      "Current iteration=300, loss=0.24596027198128223\n",
      "Current iteration=400, loss=0.2456847695990855\n",
      "Current iteration=500, loss=0.24551767912630848\n",
      "Current iteration=600, loss=0.24539976582260178\n",
      "Current iteration=700, loss=0.24530897867373547\n",
      "Current iteration=800, loss=0.24523538917370452\n",
      "Current iteration=900, loss=0.24517380161862307\n",
      "loss=0.24424090789896621\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6291388172144947\n",
      "Current iteration=100, loss=0.2462624777639691\n",
      "Current iteration=200, loss=0.24511398579293928\n",
      "Current iteration=300, loss=0.2429697146754138\n",
      "Current iteration=400, loss=0.24697028867878607\n",
      "Current iteration=500, loss=0.24178790365284664\n",
      "Current iteration=600, loss=0.2501908073087952\n",
      "Current iteration=700, loss=0.24242993033907057\n",
      "Current iteration=800, loss=0.24692666996598764\n",
      "Current iteration=900, loss=0.2415992125733554\n",
      "loss=0.2418131425530312\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290271451482715\n",
      "Current iteration=100, loss=0.24350499141899454\n",
      "Current iteration=200, loss=0.2515307954972776\n",
      "Current iteration=300, loss=0.24142793721135256\n",
      "Current iteration=400, loss=0.24971963275576536\n",
      "Current iteration=500, loss=0.2419680580590127\n",
      "Current iteration=600, loss=0.24647048850013983\n",
      "Current iteration=700, loss=0.24112901244479276\n",
      "Current iteration=800, loss=0.24934097346939296\n",
      "Current iteration=900, loss=0.2417705326541536\n",
      "loss=0.24077482636472483\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290281605444632\n",
      "Current iteration=100, loss=0.29260727084237015\n",
      "Current iteration=200, loss=0.27762716233950907\n",
      "Current iteration=300, loss=0.2856406085291551\n",
      "Current iteration=400, loss=0.27450132254129794\n",
      "Current iteration=500, loss=0.2834154624530974\n",
      "Current iteration=600, loss=0.2770855669507937\n",
      "Current iteration=700, loss=0.28467372803887986\n",
      "Current iteration=800, loss=0.2741925910733207\n",
      "Current iteration=900, loss=0.2831551157564316\n",
      "loss=0.24728643719618063\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.629269994479424\n",
      "Current iteration=100, loss=0.2515642683227021\n",
      "Current iteration=200, loss=0.24729881087232375\n",
      "Current iteration=300, loss=0.24868652724657506\n",
      "Current iteration=400, loss=0.2468103208699592\n",
      "Current iteration=500, loss=0.2483401882268163\n",
      "Current iteration=600, loss=0.2466411036235382\n",
      "Current iteration=700, loss=0.2482089472355149\n",
      "Current iteration=800, loss=0.24654556499750324\n",
      "Current iteration=900, loss=0.24813513329686104\n",
      "loss=0.2424749911145674\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6291388172144947\n",
      "Current iteration=100, loss=0.2646841015701029\n",
      "Current iteration=200, loss=0.2646145347031619\n",
      "Current iteration=300, loss=0.2646285923192565\n",
      "Current iteration=400, loss=0.2646357335160165\n",
      "Current iteration=500, loss=0.26463830602134225\n",
      "Current iteration=600, loss=0.26463916068696425\n",
      "Current iteration=700, loss=0.2646394323179347\n",
      "Current iteration=800, loss=0.2646395155664684\n",
      "Current iteration=900, loss=0.26463954016221236\n",
      "loss=0.3625862251960117\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290271451482715\n",
      "Current iteration=100, loss=0.270682170581676\n",
      "Current iteration=200, loss=0.2700653172260675\n",
      "Current iteration=300, loss=0.2700197283767436\n",
      "Current iteration=400, loss=0.2700132308320483\n",
      "Current iteration=500, loss=0.2700119316927686\n",
      "Current iteration=600, loss=0.27001163701056496\n",
      "Current iteration=700, loss=0.27001156949868044\n",
      "Current iteration=800, loss=0.2700115550328435\n",
      "Current iteration=900, loss=0.2700115524293953\n",
      "loss=0.30171805820651587\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290281605444632\n",
      "Current iteration=100, loss=0.3065429636251321\n",
      "Current iteration=200, loss=0.3113668060317949\n",
      "Current iteration=300, loss=0.3126666780338057\n",
      "Current iteration=400, loss=0.31318363146264644\n",
      "Current iteration=500, loss=0.3134064252740172\n",
      "Current iteration=600, loss=0.31350493468745\n",
      "Current iteration=700, loss=0.31354893355623115\n",
      "Current iteration=800, loss=0.3135686782205129\n",
      "Current iteration=900, loss=0.31357756186783237\n",
      "loss=0.26565165688662307\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.629269994479424\n",
      "Current iteration=100, loss=0.3614382259251577\n",
      "Current iteration=200, loss=0.35213273463831357\n",
      "Current iteration=300, loss=0.34888370099684174\n",
      "Current iteration=400, loss=0.34711474088514793\n",
      "Current iteration=500, loss=0.3459989741258522\n",
      "Current iteration=600, loss=0.3452378152177332\n",
      "Current iteration=700, loss=0.344692031227126\n",
      "Current iteration=800, loss=0.34428706746719645\n",
      "Current iteration=900, loss=0.3439791215148957\n",
      "loss=0.26774381160298544\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6291388172144947\n",
      "Current iteration=100, loss=0.9096031779939\n",
      "Current iteration=200, loss=0.9095945338694719\n",
      "Current iteration=300, loss=0.909594533785629\n",
      "Current iteration=400, loss=0.9095945337856285\n",
      "Current iteration=500, loss=0.9095945337856283\n",
      "Current iteration=600, loss=0.9095945337856285\n",
      "Current iteration=700, loss=0.9095945337856285\n",
      "Current iteration=800, loss=0.9095945337856285\n",
      "Current iteration=900, loss=0.9095945337856286\n",
      "loss=1.8399721651360472\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290271451482715\n",
      "Current iteration=100, loss=0.9081370407667781\n",
      "Current iteration=200, loss=0.9081274884314292\n",
      "Current iteration=300, loss=0.9081274883340031\n",
      "Current iteration=400, loss=0.908127488334002\n",
      "Current iteration=500, loss=0.908127488334002\n",
      "Current iteration=600, loss=0.9081274883340021\n",
      "Current iteration=700, loss=0.908127488334002\n",
      "Current iteration=800, loss=0.908127488334002\n",
      "Current iteration=900, loss=0.908127488334002\n",
      "loss=1.8489433622539946\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.6290281605444632\n",
      "Current iteration=100, loss=0.9041686367398809\n",
      "Current iteration=200, loss=0.9041593728205922\n",
      "Current iteration=300, loss=0.9041593727294884\n",
      "Current iteration=400, loss=0.904159372729488\n",
      "Current iteration=500, loss=0.904159372729488\n",
      "Current iteration=600, loss=0.9041593727294879\n",
      "Current iteration=700, loss=0.904159372729488\n",
      "Current iteration=800, loss=0.904159372729488\n",
      "Current iteration=900, loss=0.9041593727294882\n",
      "loss=1.8419900596306125\n",
      "(391, 1)\n",
      "(82033, 391)\n",
      "(246099, 65)\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] (246099, 1)\n",
      "on va auggmenter le data\n",
      "(246099, 391)\n",
      "(82033, 391)\n",
      "Current iteration=0, loss=0.629269994479424\n",
      "Current iteration=100, loss=0.9027917497865173\n",
      "Current iteration=200, loss=0.9027821840181706\n",
      "Current iteration=300, loss=0.9027821839261743\n",
      "Current iteration=400, loss=0.9027821839261736\n",
      "Current iteration=500, loss=0.9027821839261736\n",
      "Current iteration=600, loss=0.9027821839261735\n",
      "Current iteration=700, loss=0.9027821839261733\n",
      "Current iteration=800, loss=0.9027821839261733\n",
      "Current iteration=900, loss=0.9027821839261735\n",
      "loss=1.846442684764868\n",
=======
      "Current iteration=0, loss=0.629269994479423\n",
      "Current iteration=100, loss=0.247639911587246\n",
      "Current iteration=200, loss=0.2463690239862539\n",
      "Current iteration=300, loss=0.24577019733174008\n",
      "Current iteration=400, loss=0.2454896875462114\n",
      "Current iteration=500, loss=0.2453173326795431\n",
      "Current iteration=600, loss=0.24519459045419978\n",
      "Current iteration=700, loss=0.24509953628617723\n",
      "Current iteration=800, loss=0.24502218573855045\n",
      "Current iteration=900, loss=0.24495725125801598\n",
      "loss=0.24441178361308372\n",
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
      "(391, 1)\n",
      "(82033, 391)\n",
      "on y est presque\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[295], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_lambda, best_f1 \u001b[39m=\u001b[39m cross_validation_demo(np\u001b[39m.\u001b[39;49marray([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m])\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m), \u001b[39m4\u001b[39;49m, np\u001b[39m.\u001b[39;49marray([\u001b[39m10e-5\u001b[39;49m,\u001b[39m10e-4\u001b[39;49m,\u001b[39m10e-3\u001b[39;49m,\u001b[39m10e-2\u001b[39;49m]))\n",
      "Cell \u001b[0;32mIn[293], line 29\u001b[0m, in \u001b[0;36mcross_validation_demo\u001b[0;34m(degree, k_fold, lambdas)\u001b[0m\n\u001b[1;32m     27\u001b[0m         f1_score[i,j]\u001b[39m=\u001b[39mf1\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mon y est presque\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m best_degree\u001b[39m=\u001b[39mdegree[np\u001b[39m.\u001b[39;49margmax(f1_score)[\u001b[39m0\u001b[39;49m]]\n\u001b[1;32m     30\u001b[0m best_lambda\u001b[39m=\u001b[39mlambdas[np\u001b[39m.\u001b[39margmax(f1_score)[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     31\u001b[0m best_f1\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax(f1_score)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "best_lambda, best_f1, f1_score = cross_validation_demo(np.array([1,2,3,4,5]).astype(int), 4, np.array([10e-5,10e-4,10e-3,10e-2]))"
=======
    "best_lambda, best_f1, f1_score = cross_validation_demo(np.array([1,2,3,4,5]).astype(int), 4, 0)"
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03133278875903502,\n",
       " 0.0969554944715395,\n",
       " 0.10127011100936746,\n",
       " 0.13156706820136763,\n",
       " 0.08083069575188771]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 183,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data=feature_expansion(data_train_filtered_2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of the data\n",
    "def standardize(data):\n",
    "    small_value=1*10**(-9)\n",
    "    mean=np.mean(data, axis=0)\n",
    "    std=np.std(data, axis=0)+small_value\n",
    "    return((data - mean) / (std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_train_filtered\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "data_train_filtered_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_standardized = standardize(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 325)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the test set in two\n",
    "\n",
    "\n",
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8\n",
    "    you will have 80% of your data set dedicated to training\n",
    "    and the rest dedicated to testing. If ratio times the number of samples is not round\n",
    "    you can use np.floor. Also check the documentation for np.random.permutation,\n",
    "    it could be useful.\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        y: numpy array of shape (N,).\n",
    "        ratio: scalar in [0,1]\n",
    "        seed: integer.\n",
    "\n",
    "    Returns:\n",
    "        x_tr: numpy array containing the train data.\n",
    "        x_te: numpy array containing the test data.\n",
    "        y_tr: numpy array containing the train labels.\n",
    "        y_te: numpy array containing the test labels.\n",
    "    \"\"\"\n",
    "    N=int(ratio*len(x))\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # split the data based on the given ratio: \n",
    "    shuffled_data=np.random.permutation(x)\n",
    "    #print(shuffled_data)\n",
    "    np.random.seed(seed)\n",
    "    shuffled_labels=np.random.permutation(y)\n",
    "    #print(shuffled_labels)\n",
    "    x_tr=shuffled_data[:N] #train data\n",
    "    x_te=shuffled_data[N:] #test data\n",
    "    y_tr=shuffled_labels[:N]#train labels\n",
    "    y_te=shuffled_labels[N:]# test labels\n",
    "\n",
    "    return(x_tr,x_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr,x_te, y_tr, y_te=split_data(data_standardized, y_train, ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262508, 1) (262508, 276)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#print(y_tr.shape, x_tr.shape)"
=======
    "print(y_tr.shape, x_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.expand_dims(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.shape"
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification using logistic regression\n",
    "\n",
    "max_iters = 5000\n",
    "gamma = 0.5\n",
    "\n",
    " # build tx\n",
    "tx_tr = np.c_[np.ones((y_train.shape[0], 1)), data_standardized]\n",
    "initial_w=np.zeros((tx_tr.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.expand_dims(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
=======
   "execution_count": 58,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == -1, 0, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad=calculate_log_likelihood_gradient(y_train,tx_tr,initial_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w=initial_w-gamma*grad\n",
    "# print(np.min(w), np.max(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss=calculate_log_likelihood_loss(y_train,tx_tr,initial_w)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6160716356978916\n",
      "Current iteration=100, loss=0.24387140039725128\n",
      "Current iteration=200, loss=0.24166921447641773\n",
      "Current iteration=300, loss=0.2411635671984961\n",
      "Current iteration=400, loss=0.24093252425720585\n",
      "Current iteration=500, loss=0.24078481285726935\n",
      "Current iteration=600, loss=0.24067477159377584\n",
      "Current iteration=700, loss=0.24058669349151837\n",
      "Current iteration=800, loss=0.24051346093505038\n",
      "Current iteration=900, loss=0.24045112859956683\n",
      "Current iteration=1000, loss=0.24039719621012348\n",
      "Current iteration=1100, loss=0.2403499411441481\n",
      "Current iteration=1200, loss=0.24030811272553176\n",
      "Current iteration=1300, loss=0.2402707708620497\n",
      "Current iteration=1400, loss=0.24023719117153403\n",
      "Current iteration=1500, loss=0.24020680472120326\n",
      "Current iteration=1600, loss=0.24017915761426312\n",
      "Current iteration=1700, loss=0.24015388281664168\n",
      "Current iteration=1800, loss=0.2401306799514313\n",
      "Current iteration=1900, loss=0.2401093004926852\n",
      "Current iteration=2000, loss=0.24008953673063296\n",
      "Current iteration=2100, loss=0.2400712134330828\n",
      "Current iteration=2200, loss=0.24005418146969942\n",
      "Current iteration=2300, loss=0.2400383128863387\n",
      "Current iteration=2400, loss=0.24002349706366113\n",
      "Current iteration=2500, loss=0.24000963769495717\n",
      "Current iteration=2600, loss=0.23999665038861132\n",
      "Current iteration=2700, loss=0.23998446075081503\n",
      "Current iteration=2800, loss=0.23997300284038336\n",
      "Current iteration=2900, loss=0.2399622179140031\n",
      "Current iteration=3000, loss=0.2399520533997693\n",
      "Current iteration=3100, loss=0.23994246205140152\n",
      "Current iteration=3200, loss=0.23993340124641752\n",
      "Current iteration=3300, loss=0.2399248323997694\n",
      "Current iteration=3400, loss=0.2399167204706875\n",
      "Current iteration=3500, loss=0.23990903354525417\n",
      "Current iteration=3600, loss=0.23990174248089344\n",
      "Current iteration=3700, loss=0.23989482060179904\n",
      "Current iteration=3800, loss=0.23988824343652967\n",
      "Current iteration=3900, loss=0.23988198849071585\n",
      "Current iteration=4000, loss=0.23987603504917665\n",
      "Current iteration=4100, loss=0.23987036400281414\n",
      "Current iteration=4200, loss=0.23986495769649513\n",
      "Current iteration=4300, loss=0.23985979979480848\n",
      "Current iteration=4400, loss=0.23985487516312476\n",
      "Current iteration=4500, loss=0.23985016976182172\n",
      "Current iteration=4600, loss=0.23984567055189374\n",
      "Current iteration=4700, loss=0.23984136541044374\n",
      "Current iteration=4800, loss=0.23983724305479964\n",
      "Current iteration=4900, loss=0.23983329297418157\n",
      "loss=0.24488639020372494\n"
     ]
    }
   ],
   "source": [
    "w,loss= logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w,loss= logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w,loss= logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lambda_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0005\u001b[39m\n\u001b[1;32m----> 2\u001b[0m w_reg,loss_reg\u001b[38;5;241m=\u001b[39m reg_logistic_regression(y_tr, tx_tr, lambda_, initial_w, max_iters, gamma)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_tr' is not defined"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.0005\n",
    "w_reg,loss_reg= reg_logistic_regression(y_train, tx_tr, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w_reg\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w_reg' is not defined"
     ]
    }
   ],
   "source": [
    "w_reg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m build_poly(x_train, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_poly' is not defined"
     ]
    }
   ],
   "source": [
    "build_poly(x_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tx_te=np.c_[np.ones((y_te.shape[0], 1)), x_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65627, 277)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 1)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te=np.where(y_te==-1, 0, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=apply_model(tx_te, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy\n",
    "correct_predictions = np.sum(y_pred == y_te)\n",
    "total_samples = len(y_te)\n",
    "accuracy = correct_predictions / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3508144616607072"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1_score(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8506102671156689\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 80,
=======
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(test, model):\n",
    "    pred=(sigmoid(test.dot(model))>=0.32).astype(int)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=replace_nan_by_mean(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "xt_filtered=filtering_2(xt, test_data_path)"
=======
    "xt_filtered = filtering_2(xt, test_data_path)"
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data_test = feature_expansion(xt_filtered, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 325)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "augmented_data_test=feature_expansion(xt_filtered, 2)"
=======
    "xt_standardized = standardize(augmented_data_test)\n",
    "xtest = np.c_[np.ones((xt.shape[0], 1)), xt_standardized]"
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "augmented_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xt_standardized=standardize(augmented_data_test)\n",
    "xtest=np.c_[np.ones((xt.shape[0], 1)), xt_standardized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
=======
>>>>>>> 3cb5b3ab4f2fc3056f11fc0cf4a84dc18f2ad20b
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 326)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = apply_model(xtest, w)\n",
    "predictions = np.where(predictions==0,-1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, predictions, 'predictions_deg4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
