{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'build_poly' from 'implementations' (C:\\Users\\malou\\Documents\\ml-project-1-mnf\\implementations.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimplementations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_poly\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'build_poly' from 'implementations' (C:\\Users\\malou\\Documents\\ml-project-1-mnf\\implementations.py)"
     ]
    }
   ],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='./dataset_to_release/'\n",
    "train_data_path=\"./dataset_to_release/x_train.csv\"\n",
    "test_data_path=\"./dataset_to_release/x_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids=load_csv_data_all(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path=\"./dataset/x_train.csv\"\n",
    "# train_label_path=\"./dataset/y_train.csv\"\n",
    "# train_data=pd.read_csv(train_data_path)\n",
    "# train_label=pd.read_csv(train_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data points\n",
    "# xb=load_csv_data(train_data_path,sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the labels \n",
    "# yb=load_csv_data_labels(train_label_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y = np.expand_dims(yb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names from the x_train.csv and convert it into a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handeling the missing values\n",
    "\n",
    "def replace_nan_by_mean(data):\n",
    "    ''' function that handels the missing values by replacing them with the column means'''\n",
    "    nan_indices = np.isnan(data)\n",
    "    column_means = np.nanmean(data, axis=0)\n",
    "    data[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "data_train = replace_nan_by_mean(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifying that the nan values have been successfully removed\n",
    "# matrix=np.isnan(data_train)\n",
    "# num_true=np.count_nonzero(matrix)\n",
    "# num_false = matrix.size - num_true\n",
    "# print(num_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtering: we only keep relevent features\n",
    "\n",
    "def filtering(data, data_path):\n",
    "    columns = extract_first_line(data_path).split(',')\n",
    "    columns.pop(0)\n",
    "    columns_to_keep = []\n",
    "    for c in columns:\n",
    "        if c.startswith('_'):\n",
    "            columns_to_keep.append(c)\n",
    "    indices_to_keep = [columns.index(c) for c in columns_to_keep]\n",
    "    data_f = data[:, indices_to_keep]\n",
    "    return(data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_filtered=filtering(data_train, train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of the data\n",
    "def standardize(data):\n",
    "    mean=np.mean(data, axis=0)\n",
    "    std=np.std(data, axis=0)\n",
    "    return((data - mean) / (std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_standardized = standardize(data_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the test set in two\n",
    "\n",
    "\n",
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8\n",
    "    you will have 80% of your data set dedicated to training\n",
    "    and the rest dedicated to testing. If ratio times the number of samples is not round\n",
    "    you can use np.floor. Also check the documentation for np.random.permutation,\n",
    "    it could be useful.\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        y: numpy array of shape (N,).\n",
    "        ratio: scalar in [0,1]\n",
    "        seed: integer.\n",
    "\n",
    "    Returns:\n",
    "        x_tr: numpy array containing the train data.\n",
    "        x_te: numpy array containing the test data.\n",
    "        y_tr: numpy array containing the train labels.\n",
    "        y_te: numpy array containing the test labels.\n",
    "    \"\"\"\n",
    "    N=int(ratio*len(x))\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # split the data based on the given ratio: \n",
    "    shuffled_data=np.random.permutation(x)\n",
    "    #print(shuffled_data)\n",
    "    np.random.seed(seed)\n",
    "    shuffled_labels=np.random.permutation(y)\n",
    "    #print(shuffled_labels)\n",
    "    x_tr=shuffled_data[:N] #train data\n",
    "    x_te=shuffled_data[N:] #test data\n",
    "    y_tr=shuffled_labels[:N]#train labels\n",
    "    y_te=shuffled_labels[N:]# test labels\n",
    "\n",
    "    return(x_tr,x_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tr,x_te, y_tr, y_te=split_data(data_standardized, y_train, ratio=0.8)\n",
    "#y_te=np.expand_dims(y_te, 1)\n",
    "#y_tr=np.expand_dims(y_tr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_tr.shape, x_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.expand_dims(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification using logistic regression\n",
    "\n",
    "max_iters = 1000\n",
    "gamma = 0.5\n",
    "\n",
    " # build tx\n",
    "tx_tr = np.c_[np.ones((y_train.shape[0], 1)), data_standardized]\n",
    "initial_w=np.zeros((tx_tr.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == -1, 0, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad=calculate_log_likelihood_gradient(y_train,tx_tr,initial_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w=initial_w-gamma*grad\n",
    "# print(np.min(w), np.max(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss=calculate_log_likelihood_loss(y_train,tx_tr,initial_w)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6030287143641271\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w,loss\u001b[38;5;241m=\u001b[39m logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ml-project-1-mnf\\implementations.py:237\u001b[0m, in \u001b[0;36mlogistic_regression\u001b[1;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# get loss and update w.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     w\u001b[38;5;241m=\u001b[39mw\u001b[38;5;241m-\u001b[39mgamma\u001b[38;5;241m*\u001b[39mcalculate_log_likelihood_gradient(y,tx,w)\n\u001b[1;32m--> 237\u001b[0m     loss\u001b[38;5;241m=\u001b[39mcalculate_log_likelihood_loss(y,tx,w)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# log info\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\ml-project-1-mnf\\implementations.py:187\u001b[0m, in \u001b[0;36mcalculate_log_likelihood_loss\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m    185\u001b[0m N\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    186\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mtx\u001b[38;5;241m.\u001b[39mdot(w)\n\u001b[1;32m--> 187\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean((y\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(sigmoid(y_pred))\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39my)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msigmoid(y_pred))))\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w,loss= logistic_regression(y_train, tx_tr, initial_w, max_iters, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.6031907630182123\n",
      "Current iteration=100, loss=0.2520887951460211\n",
      "Current iteration=200, loss=0.25039224509073077\n",
      "Current iteration=300, loss=0.2500521566247474\n",
      "Current iteration=400, loss=0.24993664541267355\n",
      "Current iteration=500, loss=0.2498842695901215\n",
      "Current iteration=600, loss=0.24985524379278526\n",
      "Current iteration=700, loss=0.24983655399036112\n",
      "Current iteration=800, loss=0.24982309818208762\n",
      "Current iteration=900, loss=0.24981262703336746\n",
      "Current iteration=1000, loss=0.2498040556914796\n",
      "Current iteration=1100, loss=0.24979681368238313\n",
      "Current iteration=1200, loss=0.24979057224301943\n",
      "Current iteration=1300, loss=0.24978512356961943\n",
      "Current iteration=1400, loss=0.249780324917527\n",
      "Current iteration=1500, loss=0.2497760714712832\n",
      "Current iteration=1600, loss=0.2497722824081014\n",
      "Current iteration=1700, loss=0.24976889323836618\n",
      "Current iteration=1800, loss=0.24976585127206166\n",
      "Current iteration=1900, loss=0.249763112732196\n",
      "Current iteration=2000, loss=0.24976064079449578\n",
      "Current iteration=2100, loss=0.24975840418504383\n",
      "Current iteration=2200, loss=0.24975637613661977\n",
      "Current iteration=2300, loss=0.2497545335889742\n",
      "Current iteration=2400, loss=0.2497528565626392\n",
      "Current iteration=2500, loss=0.24975132766052677\n",
      "Current iteration=2600, loss=0.249749931666108\n",
      "Current iteration=2700, loss=0.24974865521604003\n",
      "Current iteration=2800, loss=0.24974748653106987\n",
      "Current iteration=2900, loss=0.24974641519312069\n",
      "loss=0.24974610137078704\n"
     ]
    }
   ],
   "source": [
    "# lambda_ = 0.0005\n",
    "# w_reg,loss_reg= reg_logistic_regression(y_train, tx_tr, lambda_, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m build_poly(x_train, \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_poly' is not defined"
     ]
    }
   ],
   "source": [
    "build_poly(x_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_te=np.c_[np.ones((y_te.shape[0], 1)), x_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te=np.where(y_te==-1, 0, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(test, model):\n",
    "    pred=(sigmoid(test.dot(model))>=0.5).astype(int)\n",
    "    return(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=apply_model(tx_te, w_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accuracy\n",
    "correct_predictions = np.sum(y_pred == y_te)\n",
    "total_samples = len(y_te)\n",
    "accuracy = correct_predictions / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=replace_nan_by_mean(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.98439905e+00],\n",
       "       [-6.71278927e-04],\n",
       "       [ 2.87138546e-03],\n",
       "       [ 1.59538068e-02],\n",
       "       [ 1.53392851e-03],\n",
       "       [ 3.76353710e-02],\n",
       "       [ 2.07579264e-02],\n",
       "       [-7.23643419e-03],\n",
       "       [ 4.91416283e-04],\n",
       "       [ 4.91416283e-04],\n",
       "       [-9.81921163e-03],\n",
       "       [ 4.61033861e-02],\n",
       "       [-3.26303386e-02],\n",
       "       [ 5.86030010e-03],\n",
       "       [ 2.26074356e-01],\n",
       "       [ 3.89504974e-02],\n",
       "       [ 2.04549791e-01],\n",
       "       [-1.29211982e-01],\n",
       "       [ 1.26911369e-01],\n",
       "       [ 1.84269871e-02],\n",
       "       [ 7.67404993e-02],\n",
       "       [-1.09742873e-01],\n",
       "       [-1.50566704e-01],\n",
       "       [-1.62424355e-01],\n",
       "       [ 1.74814008e-01],\n",
       "       [ 1.21415129e-02],\n",
       "       [ 4.29799725e-02],\n",
       "       [ 1.09373738e-02],\n",
       "       [-7.62468874e-02],\n",
       "       [ 2.45340791e-02],\n",
       "       [ 2.62838941e-01],\n",
       "       [-8.93709087e-02],\n",
       "       [ 7.63636773e-01],\n",
       "       [ 5.83425844e-02],\n",
       "       [ 3.36706373e-02],\n",
       "       [ 1.34704159e-01],\n",
       "       [-6.52823855e-02],\n",
       "       [-2.50762842e-02],\n",
       "       [-6.46279331e-02],\n",
       "       [-9.86335257e-02],\n",
       "       [-2.90634165e-01],\n",
       "       [ 2.12836319e-01],\n",
       "       [-1.70654382e-02],\n",
       "       [ 4.03529308e-01],\n",
       "       [-3.90336176e-01],\n",
       "       [ 3.63176042e-02],\n",
       "       [ 3.97145839e-02],\n",
       "       [ 1.23305940e-01],\n",
       "       [ 6.07259783e-02],\n",
       "       [ 4.67729404e-04],\n",
       "       [-3.29423725e-02],\n",
       "       [ 2.12610013e-01],\n",
       "       [ 9.36415041e-02],\n",
       "       [-2.21534671e-02],\n",
       "       [-1.24664783e-02],\n",
       "       [-1.20603812e-01],\n",
       "       [-5.97489189e-02],\n",
       "       [ 4.56574966e-02],\n",
       "       [ 4.74162132e-03],\n",
       "       [ 1.16932460e-03],\n",
       "       [ 1.69241553e-01],\n",
       "       [-1.13364919e-01],\n",
       "       [ 3.17946062e-02],\n",
       "       [-1.85402786e-02],\n",
       "       [-1.64476946e-01],\n",
       "       [-1.03937528e-01],\n",
       "       [-3.45575572e-02],\n",
       "       [ 1.41939992e-01],\n",
       "       [ 1.56886992e-02],\n",
       "       [ 2.63380809e-02],\n",
       "       [-8.93762204e-02],\n",
       "       [-5.15897472e-02],\n",
       "       [ 1.92704481e-01],\n",
       "       [ 1.03932296e-02],\n",
       "       [-5.39275320e-02],\n",
       "       [ 8.49469359e-05]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_filtered=filtering(xt, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 75)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xt_filtered_standardized=standardize(xt_filtered)\n",
    "xtest=np.c_[np.ones((xt.shape[0], 1)), xt_filtered_standardized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 76)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=apply_model(xtest, w)\n",
    "predictions=np.where(predictions==0,-1, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, predictions, 'predictions_v1_with_logistic_regression.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
